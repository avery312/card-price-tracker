import streamlit as st
import pandas as pd
from datetime import datetime
import requests
from bs4 import BeautifulSoup
import re 
import uuid
from streamlit_gsheets import GSheetsConnection

# === é…ç½®åŠå¸¸é‡ ===
SHEET_NAME = "æ•°æ®è¡¨"  # ä½ çš„ Google Sheets è¡¨æ ¼åº•éƒ¨æ ‡ç­¾åç§°ï¼Œè¯·ç¡®ä¿ä¸ä½ çš„è¡¨æ ¼åç§°ä¸€è‡´
YUYU_TEI_BASE_IMAGE_URL = 'https://card.yuyu-tei.jp/opc/front/' 
# ç§»é™¤ DB_NAME å’Œ IMAGE_FOLDER å¸¸é‡

# === æ•°æ®åº“å‡½æ•° (ç°ä¸º Google Sheets å‡½æ•°) ===

def get_gsheets_connection():
    """å»ºç«‹ä¸ Google Sheets çš„è¿æ¥"""
    # è¿™é‡Œçš„ 'gsheets' å¯¹åº” .streamlit/secrets.toml ä¸­çš„ [gsheets] é…ç½®
    return st.connection("gsheets", type=GSheetsConnection)

# init_db å‡½æ•°ç°åœ¨ä»…ç”¨äºåŠ è½½æ•°æ®å’Œç¡®ä¿è¿æ¥æ­£å¸¸
def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“ï¼Œç¡®ä¿è¿æ¥æ­£å¸¸å¹¶è¿”å›æ•°æ®"""
    try:
        conn = get_gsheets_connection()
        # å°è¯•è¯»å–æ•°æ®ï¼Œç¡®ä¿è¡¨å­˜åœ¨ï¼ˆåœ¨ Sheets ä¸­å³ä¸ºç¡®ä¿å·¥ä½œè¡¨å­˜åœ¨ï¼‰
        df = conn.read(worksheet=SHEET_NAME)
        return df
    except Exception as e:
        st.error(f"æ— æ³•è¿æ¥åˆ° Google Sheets æˆ–è¯»å–å·¥ä½œè¡¨ '{SHEET_NAME}'ã€‚è¯·æ£€æŸ¥ secrets.toml é…ç½®å’Œå·¥ä½œè¡¨åç§°æ˜¯å¦æ­£ç¡®ã€‚é”™è¯¯: {e}")
        return pd.DataFrame() # è¿”å›ç©º DataFrame é¿å…åº”ç”¨å´©æºƒ

# ç§»é™¤ init_db() ä¸­çš„ SQLite è¡¨ç»“æ„åˆ›å»ºå’Œåˆ—æ£€æŸ¥é€»è¾‘

# æ›¿æ¢ add_card å‡½æ•°
def add_card(name, number, card_set, rarity, price, quantity, date, image_url=None):
    conn = get_gsheets_connection()
    
    # 1. åˆ›å»ºæ–°çš„è®°å½•è¡Œ
    new_data = pd.DataFrame([{
        "id": str(uuid.uuid4()), # ä½¿ç”¨ UUID ä½œä¸ºå”¯ä¸€ID
        "card_name": name,
        "card_number": number,
        "card_set": card_set,
        "rarity": rarity,
        "price": price,
        "quantity": quantity,
        "date": date.strftime('%Y-%m-%d'), # ç¡®ä¿æ—¥æœŸæ ¼å¼ç»Ÿä¸€
        "image_url": image_url if image_url else ""
    }])
    
    # 2. å°†æ•°æ®è¿½åŠ åˆ° Google Sheets
    conn.append(data=new_data, worksheet=SHEET_NAME)

# æ›¿æ¢ delete_card å‡½æ•°
def delete_card(card_id):
    conn = get_gsheets_connection()
    df = load_data(conn) # é‡æ–°åŠ è½½å½“å‰æ‰€æœ‰æ•°æ®
    
    # è¿‡æ»¤æ‰è¦åˆ é™¤çš„è¡Œ
    df_updated = df[df['id'] != str(card_id)]
    
    # å°†æ•´ä¸ªæ›´æ–°åçš„ DataFrame å†™å› Google Sheets
    # æ³¨æ„ï¼šGoogle Sheets å†™å…¥éœ€è¦è¦†ç›–æ¨¡å¼
    conn.write(data=df_updated, worksheet=SHEET_NAME)

# æ›¿æ¢ load_data å‡½æ•°
def load_data(conn=None):
    if conn is None:
        conn = get_gsheets_connection()
        
    try:
        # è¯»å–æ•´ä¸ªå·¥ä½œè¡¨åˆ° DataFrame
        df = conn.read(worksheet=SHEET_NAME, ttl=5) # ttl=5 ç§’ï¼Œæ§åˆ¶æ•°æ®åˆ·æ–°é¢‘ç‡
        # ç¡®ä¿ id åˆ—æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œä»¥ä¾¿æ¯”è¾ƒ
        df['id'] = df['id'].astype(str)
        return df
    except Exception as e:
        st.error(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

# ç§»é™¤ save_uploaded_image å‡½æ•°

# ç½‘é¡µæŠ“å–å‡½æ•° (ä¿æŒä¸å˜ï¼Œå› ä¸ºä¸æ¶‰åŠæœ¬åœ°æ–‡ä»¶)
@st.cache_data(ttl=3600) 
def scrape_card_data(url):
    st.info(f"æ­£åœ¨å°è¯•ä» {url} æŠ“å–æ•°æ®...")
    if not url.startswith("http"):
        return {"error": "ç½‘å€æ ¼å¼ä¸æ­£ç¡®ï¼Œå¿…é¡»ä»¥ http æˆ– https å¼€å¤´ã€‚"}
    
    # (ç½‘é¡µæŠ“å–é€»è¾‘ä¸å˜...)
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status() 
        response.encoding = 'EUC-JP'
        soup = BeautifulSoup(response.content, 'html.parser')

        # --- 1. æå– ä¸»æ ‡é¢˜è¡Œ (åŒ…å« ç­‰çº§, åç§°, ç‰ˆæœ¬) ---
        name_tag = soup.select_one('h1')
        full_title = name_tag.get_text(strip=True) if name_tag else ""
        
        card_name = "N/A"
        card_rarity = "N/A"
        card_set = "N/A"
        
        if full_title:
            # 1. æå– ç­‰çº§ (Rarity)
            rarity_match = re.match(r'^([A-Z0-9\-]+)', full_title)
            if rarity_match:
                card_rarity = rarity_match.group(1).strip()
                remainder = full_title[len(rarity_match.group(0)):].strip()
            else:
                remainder = full_title
                card_rarity = "N/A"
            
            # 2. æå– åç§°
            name_match = re.match(r'([^(\s]+)', remainder)
            if name_match:
                card_name = name_match.group(1).strip()
            else:
                card_name = remainder.strip() 

            # 3. æå– ç‰ˆæœ¬ (Set)
            set_matches = re.findall(r'\(([^)]+)\)', full_title)
            if set_matches:
                card_set = " / ".join(set_matches).strip()
            else:
                card_set = "N/A"
        
        # --- 4. æå– å¡ç‰Œç¼–å· (OP07-064) ---
        card_number = "N/A"
        number_pattern = r'[A-Z0-9]{2,}\-\d{2,}'
        
        page_text = soup.get_text()
        number_matches = re.findall(number_pattern, page_text)
        
        if number_matches:
            card_number = number_matches[0] 

        # --- 5. æå– å›¾ç‰‡é“¾æ¥ ---
        match = re.search(r'yuyu-tei\.jp/sell/opc/card/([^/]+)/(\d+)', url)
        image_url = None
        if match:
            category_path = match.group(1) 
            card_id = match.group(2)       
            image_url = YUYU_TEI_BASE_IMAGE_URL + category_path + '/' + card_id + '.jpg'

        return {
            "card_name": card_name,
            "card_number": card_number,
            "card_set": card_set,
            "card_rarity": card_rarity,
            "image_url": image_url,
            "error": None
        }

    except requests.exceptions.RequestException as e:
        return {"error": f"ç½‘ç»œé”™è¯¯æˆ–æ— æ³•è®¿é—®: {e}"}
    except Exception as e:
        return {"error": f"è§£æç½‘é¡µæ—¶å‘ç”Ÿé”™è¯¯: {e}. è¯·æ£€æŸ¥HTMLç»“æ„æ˜¯å¦å˜åŒ–ã€‚"}


# --- Streamlit Session State & UI ---
if 'scrape_result' not in st.session_state:
    st.session_state['scrape_result'] = {}
    
def clear_all_data():
    st.session_state['scrape_result'] = {} 
    st.session_state['scrape_url_input'] = ""
    
# === ç•Œé¢å¸ƒå±€ ===
st.set_page_config(page_title="å¡ç‰Œè¡Œæƒ…åˆ†æPro", page_icon="ğŸ“ˆ", layout="wide")
df = init_db() # ä½¿ç”¨æ–°çš„ init_db åŠ è½½æ•°æ®

# --- ä¾§è¾¹æ ï¼šå½•å…¥ ---
with st.sidebar:
    st.header("ğŸŒ ç½‘é¡µè‡ªåŠ¨å¡«å…… (yuyu-tei)")
    
    scrape_url = st.text_input("è¾“å…¥å¡ç‰Œè¯¦æƒ…é¡µç½‘å€:", 
                               key='scrape_url_input') 
    
    col_scrape_btn, col_clear_btn = st.columns(2)
    
    with col_scrape_btn:
        if st.button("ä¸€é”®æŠ“å–å¹¶å¡«å……", type="secondary"):
            if not scrape_url:
                 st.warning("è¯·è¾“å…¥ç½‘å€åå†ç‚¹å‡»æŠ“å–ã€‚")
            else:
                st.session_state['scrape_result'] = scrape_card_data(scrape_url)
                if st.session_state['scrape_result']['error']:
                    st.error(st.session_state['scrape_result']['error'])
                else:
                    st.success("æ•°æ®æŠ“å–å®Œæˆï¼Œå·²è‡ªåŠ¨å¡«å……ä¸‹æ–¹è¡¨å•ã€‚")
                 
    with col_clear_btn:
        st.button("ä¸€é”®æ¸…é™¤å½•å…¥å†…å®¹", type="primary", on_click=clear_all_data)

    st.divider()
    st.header("ğŸ“ æ‰‹åŠ¨å½•å…¥/ä¿®æ­£")
    
    # é¢„å¡«å……æŠ“å–ç»“æœ
    name_default = st.session_state['scrape_result'].get('card_name', "")
    number_default = st.session_state['scrape_result'].get('card_number', "")
    set_default = st.session_state['scrape_result'].get('card_set', "")
    rarity_default = st.session_state['scrape_result'].get('card_rarity', "")
    img_url_default = st.session_state['scrape_result'].get('image_url', "")

    # å½•å…¥å­—æ®µé¡ºåº: 1.ç¼–å· -> 2.åç§° -> 3.ç‰ˆæœ¬ -> 4.ç­‰çº§ -> 5.ä»·æ ¼ -> 6.æ•°é‡ -> 7.æ—¥æœŸ
    card_number_in = st.text_input("1. å¡ç‰Œç¼–å·", value=number_default)
    name_in = st.text_input("2. å¡ç‰Œåç§° (å¿…å¡«)", value=name_default)
    set_in = st.text_input("3. ç³»åˆ—/ç‰ˆæœ¬", value=set_default) 
    rarity_in = st.text_input("4. ç­‰çº§ (Rarity)", value=rarity_default) 
    
    # --- å­—æ®µè°ƒæ•´ï¼šç§»é™¤å“ç›¸ï¼Œå¢åŠ æ•°é‡ ---
    price_in = st.number_input("5. ä»·æ ¼ (Â¥)", min_value=0.0, step=10.0)
    quantity_in = st.number_input("6. æ•°é‡ (å¼ )", min_value=1, step=1)
    # ------------------------------------
    
    date_in = st.date_input("7. å½•å…¥æ—¥æœŸ", datetime.now())

    st.divider()
    st.write("ğŸ–¼ï¸ å¡ç‰Œå›¾ç‰‡ (è¯·ä½¿ç”¨ç½‘ç»œé“¾æ¥)")
    
    # ç§»é™¤ radio é€‰é¡¹ï¼Œåªä¿ç•™ URL è¾“å…¥
    image_url_input = st.text_input("è¾“å…¥å›¾ç‰‡ç½‘å€ (URL)", value=img_url_default)
    
    final_image_path = None
    if image_url_input:
        try:
            st.image(image_url_input, caption="é¢„è§ˆ", use_container_width=True)
            final_image_path = image_url_input
        except: 
            st.error("æ— æ³•åŠ è½½è¯¥é“¾æ¥çš„å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥ç½‘å€æ˜¯å¦æ­£ç¡®ã€‚")


    if st.button("æäº¤å½•å…¥", type="primary"):
        if name_in:
            # final_image_path å·²ç»æ˜¯ URL
            
            # è°ƒç”¨æ›´æ–°åçš„ add_card å‡½æ•° (price, quantity)
            add_card(name_in, card_number_in, set_in, rarity_in, price_in, quantity_in, date_in, final_image_path)
            st.session_state['scrape_result'] = {}
            st.success(f"å·²å½•å…¥: {name_in} - Â¥{price_in} x {quantity_in} å¼ ")
            
            # æ¸…é™¤ç¼“å­˜å¹¶é‡æ–°åŠ è½½æ•°æ®ï¼Œä»¥ä¾¿åœ¨ä¸»é¡µé¢å³æ—¶æ˜¾ç¤º
            st.cache_data.clear() 
            st.rerun()
        else:
            st.error("å¡ç‰Œåç§°ä¸èƒ½ä¸ºç©ºï¼")

# --- ä¸»é¡µé¢ (ä¿æŒä¸å˜ï¼Œå› ä¸º load_data è¿”å›çš„ä»æ˜¯ DataFrame) ---
st.title("ğŸ“ˆ å¡ç‰Œå†å²ä¸ä»·æ ¼åˆ†æ Pro")

if df.empty:
    st.info("ğŸ‘‹ æ¬¢è¿ï¼è¯·åœ¨å·¦ä¾§å½•å…¥ä½ çš„ç¬¬ä¸€å¼ å¡ç‰Œæ•°æ®ï¼Œæˆ–æ£€æŸ¥ Google Sheets è¿æ¥ã€‚")
else:
    # é¢„å¤„ç†
    # ç¡®ä¿ 'id' åˆ—æ˜¯å­—ç¬¦ä¸²ï¼Œä¸” 'date' åˆ—æ˜¯ datetime å¯¹è±¡
    df['id'] = df['id'].astype(str) 
    df['date_dt'] = pd.to_datetime(df['date'])
    df['image_url'] = df['image_url'].fillna('')
    df['rarity'] = df['rarity'].fillna('')
    df['quantity'] = df['quantity'].fillna(1).astype(int) 
    
    # ... (å…¶ä½™å±•ç¤ºå’Œåˆ†æé€»è¾‘ä¿æŒä¸å˜)
    
    # (æ­¤å¤„çœç•¥å…¶ä½™å±•ç¤ºå’Œåˆ†æé€»è¾‘ï¼Œè¯·åœ¨æ‚¨çš„ app.py ä¸­ä¿ç•™)

    # ... (æ¥ä¸‹æ¥çš„ä»£ç é€»è¾‘ä¸åŸä»£ç ä¿æŒä¸€è‡´)

    # --- ğŸ—‘ï¸ æ•°æ®ç®¡ç† ---
    with st.expander("ğŸ—‘ï¸ æ•°æ®ç®¡ç† (åˆ é™¤è®°å½•)"):
        if not df.empty:
            # ä½¿ç”¨æ•´ä¸ª DataFrameï¼Œè€Œä¸æ˜¯ filtered_dfï¼Œä»¥ç¡®ä¿èƒ½åˆ é™¤æ‰€æœ‰è®°å½•
            df_display = df.sort_values(by='date_dt', ascending=False)
            
            # æ›´æ–° del_label ä»¥æ˜¾ç¤ºæ•°é‡
            df_display['del_label'] = df_display.apply(lambda x: f"ID:{x['id'][:8]}... | {x['date']} | {x['card_name']} ({x['card_number']}) | Â¥{x['price']} x {x['quantity']}", axis=1)
            
            del_select = st.selectbox("é€‰æ‹©è¦åˆ é™¤çš„è®°å½•:", df_display['del_label'])
            
            if st.button("ç¡®è®¤åˆ é™¤é€‰ä¸­è®°å½•"):
                # ä» del_select ä¸­æå–å®Œæ•´çš„ UUID
                selected_uuid_prefix = del_select.split("|")[0].replace("ID:", "").replace("...", "").strip()
                # æ‰¾åˆ°åŒ¹é… UUID å‰ç¼€çš„å®Œæ•´ ID
                full_id_to_delete = df_display[df_display['id'].str.startswith(selected_uuid_prefix)]['id'].iloc[0]
                
                delete_card(full_id_to_delete)
                st.success("å·²åˆ é™¤ï¼")
                st.cache_data.clear() 
                st.rerun()

# å‰©ä½™ä»£ç ä¿æŒåŸæ ·...