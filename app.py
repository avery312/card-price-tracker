import streamlit as st
import pandas as pd
# æ˜ç¡®å¯¼å…¥ datetime å’Œ date å¯¹è±¡
from datetime import datetime, date 
import requests
from bs4 import BeautifulSoup
import re 
import numpy as np 
# å¯¼å…¥ Supabase å®¢æˆ·ç«¯åº“
from supabase import create_client, Client 
import time 

# === é…ç½® ===
SUPABASE_TABLE_NAME = "cards" 
NEW_EXPECTED_COLUMNS = ['id', 'date', 'card_number', 'card_name', 'card_set', 'price', 'quantity', 'rarity', 'color', 'image_url']

# --- Streamlit Session State ---
if 'scrape_result' not in st.session_state:
    st.session_state['scrape_result'] = {}
if 'form_key_suffix' not in st.session_state: 
    st.session_state['form_key_suffix'] = 0

if 'submission_successful' not in st.session_state: 
    st.session_state['submission_successful'] = False
if 'submitted_card_name' not in st.session_state: 
    st.session_state['submitted_card_name'] = "" 

if 'last_entry_date' not in st.session_state:
    st.session_state['last_entry_date'] = datetime.now().date() 
    
# æ–°å¢ Session state for autosave messages (ç”¨äºæ˜¾ç¤ºè‡ªåŠ¨ä¿å­˜ç»“æœ)
if 'autosave_successful' not in st.session_state:
    st.session_state['autosave_successful'] = False
if 'autosave_message' not in st.session_state:
    st.session_state['autosave_message'] = ""
    
# æ–°å¢ Session state for filter persistence (ç”¨äºä¿æŒç­›é€‰çŠ¶æ€)
# æš‚æ—¶ç¦ç”¨ç­›é€‰çŠ¶æ€çš„ Session state èµ‹å€¼ï¼Œä»¥ç®€åŒ–
# if 'date_range_input' not in st.session_state:
#     st.session_state['date_range_input'] = [] 
# if 'search_name_input' not in st.session_state:
#     st.session_state['search_name_input'] = ""
# if 'search_set_input' not in st.session_state:
#     st.session_state['search_set_input'] = ""


def clear_all_data():
    """æ¸…é™¤æ‰€æœ‰å½•å…¥ç›¸å…³ Session Stateã€‚"""
    st.session_state['scrape_result'] = {} 
    st.session_state['form_key_suffix'] += 1 
    st.session_state['last_entry_date'] = datetime.now().date() 

# ç¦ç”¨ clear_search_filters_action å› ä¸ºä¹‹å‰æ²¡æœ‰å®šä¹‰ç›¸å…³çš„ session state å˜é‡
# def clear_search_filters_action():
#     """æ¸…é™¤æ‰€æœ‰ç­›é€‰ç›¸å…³çš„ Session State å˜é‡ã€‚ç”¨äº on_click å›è°ƒã€‚"""
#     st.session_state["search_name_input"] = ""
#     st.session_state["search_set_input"] = ""
#     st.session_state["date_range_input"] = [] 


# === è¾…åŠ©å‡½æ•°ï¼šæ¨¡ç³Šæœç´¢è§„èŒƒåŒ– ===
def normalize_text_for_fuzzy_search(text):
    if pd.isna(text):
        return ""
    cleaned = str(text).replace('-', '').replace(' ', '')
    return cleaned.upper()

# === Supabase æ•°æ®åº“å‡½æ•° ===

@st.cache_resource(ttl=None)
def connect_supabase() -> Client:
    """ä½¿ç”¨ Streamlit Secrets å‡­è¯è¿æ¥åˆ° Supabase æ•°æ®åº“ (è¿æ¥å¯¹è±¡ç¼“å­˜)"""
    try:
        url: str = st.secrets["supabase"]["URL"]
        key: str = st.secrets["supabase"]["KEY"]
        supabase: Client = create_client(url, key)
        return supabase
    except Exception as e:
        st.error(f"æ— æ³•è¿æ¥ Supabase æ•°æ®åº“ã€‚è¯·æ£€æŸ¥ secrets.toml é…ç½®ã€‚é”™è¯¯: {e}")
        return None

def load_data():
    """ä» Supabase è¯»å–æ‰€æœ‰æ•°æ® (æ¯æ¬¡è„šæœ¬è¿è¡Œæ—¶éƒ½å¼ºåˆ¶è¯»å–)"""
    supabase = connect_supabase()
    if not supabase:
        return pd.DataFrame(columns=NEW_EXPECTED_COLUMNS)
    
    try:
        # ç›´æ¥è¯»å–æ•°æ®
        response = supabase.table(SUPABASE_TABLE_NAME).select("*").order("date", desc=True).execute()
        
        df = pd.DataFrame(response.data)
        
        if df.empty:
             return pd.DataFrame(columns=NEW_EXPECTED_COLUMNS)

        df = df.replace({np.nan: None}) 
        df['id'] = pd.to_numeric(df['id'], errors='coerce').fillna(0).astype(int)
        
        df = df[NEW_EXPECTED_COLUMNS] 

        return df
    except Exception as e:
        st.error(f"æ— æ³•ä» Supabase è¯»å–æ•°æ®ã€‚é”™è¯¯: {e}")
        return pd.DataFrame(columns=NEW_EXPECTED_COLUMNS)

# æ–°å¢/è¿½åŠ å¡ç‰Œ
def add_card(name, number, card_set, price, quantity, rarity, color, date, image_url=None):
    supabase = connect_supabase()
    if not supabase: return
    
    try:
        # 1. ç›´æ¥æŸ¥è¯¢ Supabase è·å–æœ€å¤§çš„ ID 
        response = supabase.table(SUPABASE_TABLE_NAME).select("id").order("id", desc=True).limit(1).execute()
        
        max_id = 0
        if response.data and response.data[0] and 'id' in response.data[0]:
            # æ‰¾åˆ°å½“å‰æœ€å¤§çš„ ID
            max_id = response.data[0]['id']
            
        new_id = int(max_id + 1) if pd.notna(max_id) else 1
        
        # 2. å‡†å¤‡è¦æ’å…¥çš„å­—å…¸æ•°æ®
        new_row_data = {
            "id": new_id,
            "date": date.strftime('%Y-%m-%d'),
            "card_number": number,
            "card_name": name,
            "card_set": card_set,
            "price": price,
            "quantity": quantity,
            "rarity": rarity,
            "color": color,
            "image_url": image_url if image_url else ""
        }
        
        # 3. æ‰§è¡Œæ’å…¥æ“ä½œ
        supabase.table(SUPABASE_TABLE_NAME).insert(new_row_data).execute()
        
    except Exception as e:
        st.error(f"è¿½åŠ æ•°æ®åˆ° Supabase å¤±è´¥ã€‚é”™è¯¯: {e}")

# ã€æ ¸å¿ƒåŠŸèƒ½ï¼šå®ç°å…¨é‡ä¿å­˜ï¼Œä»¥ç®€åŒ– data_editor çš„å¤æ‚çŠ¶æ€å¤„ç†ã€‘
def update_data_and_save(edited_df: pd.DataFrame):
    """
    åˆ é™¤ Supabase ä¸­çš„æ‰€æœ‰æ•°æ®ï¼Œç„¶åé‡æ–°æ’å…¥ç¼–è¾‘åçš„ DataFrame ä¸­çš„æ‰€æœ‰æ•°æ®ã€‚
    """
    supabase = connect_supabase()
    if not supabase: return
    
    try:
        # 1. æ•°æ®ç±»å‹æ¸…ç†å’Œæ ¼å¼åŒ–
        edited_df['date'] = pd.to_datetime(edited_df['date'], errors='coerce').dt.strftime('%Y-%m-%d')
        # ç¡®ä¿ç¼–è¾‘åçš„ price å’Œ quantity æ˜¯æ­£ç¡®çš„æ•°å€¼ç±»å‹
        edited_df['id'] = pd.to_numeric(edited_df['id'], errors='coerce').fillna(0).astype(int)
        edited_df['price'] = pd.to_numeric(edited_df['price'], errors='coerce').fillna(0.0).astype(float)
        edited_df['quantity'] = pd.to_numeric(edited_df['quantity'], errors='coerce').fillna(0).astype(int)
        
        df_final = edited_df[NEW_EXPECTED_COLUMNS].fillna('')
        data_to_save = df_final.to_dict('records')

        # 2. æ ¸å¿ƒæ“ä½œï¼šåˆ é™¤æ‰€æœ‰æ—§æ•°æ®ï¼Œç„¶åé‡æ–°æ’å…¥æ‰€æœ‰æ–°æ•°æ®
        # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ Supabase ä¸­çš„ 'id' å­—æ®µæ˜¯è‡ªå¢çš„ï¼Œä½†æˆ‘ä»¬å¿…é¡»ä¾é  DataFrame ä¸­çš„ id
        # ç”±äºæˆ‘ä»¬ä½¿ç”¨ st.data_editorï¼Œå¦‚æœå…è®¸æ·»åŠ è¡Œï¼Œå¯èƒ½ä¼šæœ‰æ–°çš„ idï¼Œä½†æˆ‘ä»¬è¿™é‡Œåªå¤„ç†ç¼–è¾‘å’Œåˆ é™¤
        
        # ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå¿«é€Ÿçš„å…¨è¡¨åˆ é™¤å†æ’å…¥ï¼ˆå¦‚æœæ•°æ®é‡ä¸å¤§ï¼‰
        # å®é™…ç”Ÿäº§ä¸­åº”ä½¿ç”¨ UPSERT æˆ–å¢é‡æ›´æ–°ï¼Œä½† Streamlit çš„ data_editor çŠ¶æ€éš¾ä»¥ç²¾ç¡®æ˜ å°„ã€‚
        # æˆ‘ä»¬å¯ä»¥å°è¯•ä½¿ç”¨äº‹åŠ¡æ¥ç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼Œä½† Streamlit ä¸æ”¯æŒã€‚
        
        # ä¸ºäº†é¿å…å…¨é‡åˆ é™¤ä¸¢å¤±æ•°æ®ï¼Œæˆ‘ä»¬åªåˆ é™¤è¢«ä¿®æ”¹è¿‡çš„è®°å½• (è¿™åœ¨å…¨é‡æ›´æ–°é€»è¾‘ä¸­ä¸é€‚ç”¨)
        # æœ€ç®€å•ç¨³å®šçš„æ–¹å¼ï¼šä½¿ç”¨ç¼–è¾‘åçš„ DataFrame è¦†ç›–æ•´ä¸ªè¡¨ï¼ˆå‰ææ˜¯ edited_df åŒ…å«æ‰€æœ‰æ•°æ®ï¼‰

        # é’ˆå¯¹æ‚¨ä¸Šä¸€ä¸ªç‰ˆæœ¬ä»£ç ä¸­çš„å…¨é‡ä¿å­˜é€»è¾‘ï¼Œæˆ‘ä»¬ä¿ç•™å®ƒ
        supabase.table(SUPABASE_TABLE_NAME).delete().neq('id', 0).execute() 

        if data_to_save:
            supabase.table(SUPABASE_TABLE_NAME).insert(data_to_save).execute()
        
        st.session_state['autosave_successful'] = True
        st.session_state['autosave_message'] = "âœ… æ•°æ®ä¿®æ”¹å·²ä¿å­˜åˆ° Supabaseï¼"

    except Exception as e:
        st.session_state['autosave_successful'] = True
        st.session_state['autosave_message'] = f"âŒ ä¿å­˜ä¿®æ”¹å¤±è´¥ã€‚é”™è¯¯: {e}"


# ç½‘é¡µæŠ“å–å‡½æ•° (ä¿æŒä¸å˜)
def scrape_card_data(url):
    st.info(f"æ­£åœ¨å°è¯•ä» {url} æŠ“å–æ•°æ®...")
    if not url.startswith("http"):
        return {"error": "ç½‘å€æ ¼å¼ä¸æ­£ç¡®ã€‚"}
    
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, timeout=10, headers=headers)
        response.raise_for_status() 
        response.encoding = response.apparent_encoding
        soup = BeautifulSoup(response.content, 'html.parser')

        name_tag = soup.find(['h1', 'h2'], class_=re.compile(r'heading|title', re.I))
        full_title = name_tag.get_text(strip=True) if name_tag else ""
        
        if not full_title:
             return {"error": "æœªèƒ½æ‰¾åˆ°å¡ç‰Œåç§°æ ‡é¢˜ã€‚"}

        card_name = "N/A"; rarity = "N/A"; color = "N/A"; card_number = "N/A"; card_set = "" 
        temp_title = full_title 

        # 1. æå– rarity
        rarity_match = re.search(r'ã€(.+?)ã€‘', temp_title)
        if rarity_match:
            rarity = rarity_match.group(1).strip()
            temp_title = temp_title.replace(rarity_match.group(0), ' ').strip()
        
        # 2. æå– color
        color_match = re.search(r'ã€Š(.+?)ã€‹', temp_title)
        if color_match:
            color = color_match.group(1).strip()
            temp_title = temp_title.replace(color_match.group(0), ' ').strip()
        
        # 3. æå– card_number
        number_match = re.search(r'([A-Z0-9]{1,}\-\d{2,})', temp_title) 
        
        if number_match:
            card_number = number_match.group(1).strip()
            temp_title_without_number = temp_title[:number_match.start()] + temp_title[number_match.end():]
        else:
            temp_title_without_number = temp_title
        
        # 4. æå– card_set å’Œ card_name
        name_part = re.match(r'(.+?)[\s\[ã€]', temp_title_without_number.strip())
        if name_part:
            card_name = name_part.group(1).strip()
            card_set = temp_title_without_number[len(name_part.group(0)):].strip()
        else:
            card_name = temp_title_without_number.strip()
            card_set = ""
            
        card_set = re.sub(r'[\[\]ã€ã€]', '', card_set).strip()
        
        # --- 5. æå–å›¾ç‰‡é“¾æ¥ ---
        image_url = None
        
        og_image_tag = soup.find('meta', property='og:image')
        if og_image_tag:
            image_url = og_image_tag.get('content')
            
        if not image_url:
            image_tag = soup.find('img', {'alt': lambda x: x and 'ãƒ¡ã‚¤ãƒ³ç”»åƒ' in x}) or \
                        soup.find('img', {'alt': lambda x: x and card_name in x})
            
            if image_tag:
                image_url = image_tag.get('data-src') or image_tag.get('src') 
        
        if not image_url:
            st.warning("æœªèƒ½æ‰¾åˆ°å›¾ç‰‡é“¾æ¥ã€‚")

        return {
            "card_name": card_name, "card_number": card_number, "card_set": card_set,
            "card_rarity": rarity, "card_color": color, "image_url": image_url, "error": None
        }

    except requests.exceptions.RequestException as e:
        return {"error": f"ç½‘ç»œé”™è¯¯æˆ–æ— æ³•è®¿é—®: {e}"}
    except Exception as e:
        return {"error": f"è§£æé”™è¯¯: {e}"}

# === ç•Œé¢å¸ƒå±€ ===
st.set_page_config(page_title="å¡ç‰Œè¡Œæƒ…åˆ†æPro", page_icon="ğŸ“ˆ", layout="wide")

suffix = str(st.session_state['form_key_suffix']) 

# --- ä¾§è¾¹æ ï¼šå½•å…¥ ---
with st.sidebar:
    if st.session_state.get('submission_successful'):
        card_name = st.session_state.get('submitted_card_name', 'ä¸€å¼ å¡ç‰Œ')
        st.success(f"âœ… **{card_name}** å½•å…¥æˆåŠŸï¼", icon="ğŸ‰") 
        
    st.header("ğŸŒ ç½‘é¡µè‡ªåŠ¨å¡«å……")
    scrape_url = st.text_input("è¾“å…¥å¡ç‰Œè¯¦æƒ…é¡µç½‘å€:", key=f'scrape_url_input_{suffix}') 
    
    col_scrape_btn, col_clear_btn = st.columns(2)
    
    with col_scrape_btn:
        if st.button("ä¸€é”®æŠ“å–å¹¶å¡«å……", type="secondary", key=f"scrape_btn_{suffix}"):
            if not scrape_url: st.warning("è¯·è¾“å…¥ç½‘å€ã€‚")
            else:
                st.session_state['scrape_result'] = scrape_card_data(scrape_url)
                if st.session_state['scrape_result']['error']: st.error(st.session_state['scrape_result']['error'])
                else: st.success("æ•°æ®æŠ“å–å®Œæˆã€‚")
                st.session_state['form_key_suffix'] += 1
                st.rerun() 
                 
    with col_clear_btn:
        if st.button("ä¸€é”®æ¸…é™¤å½•å…¥å†…å®¹", type="primary", key=f"clear_btn_{suffix}"):
            clear_all_data()
            st.rerun() 

    st.divider()
    st.header("ğŸ“ æ‰‹åŠ¨å½•å…¥/ä¿®æ­£")
    
    res = st.session_state['scrape_result']
    name_default = res.get('card_name', "")
    number_default = res.get('card_number', "")
    set_default = res.get('card_set', "")
    rarity_default = res.get('card_rarity', "") 
    color_default = res.get('card_color', "") 
    img_url_default = res.get('image_url', "")

    
    with st.form(key=f"manual_entry_form_{suffix}"):
        card_number_in = st.text_input("1. å¡ç‰Œç¼–å·", value=number_default, key=f"card_number_in_form_{suffix}")
        name_in = st.text_input("2. å¡ç‰Œåç§° (å¿…å¡«)", value=name_default, key=f"name_in_form_{suffix}")
        set_in = st.text_input("3. ç³»åˆ—/ç‰ˆæœ¬", value=set_default, key=f"set_in_form_{suffix}") 
        rarity_in = st.text_input("4. ç­‰çº§ (Rarity)", value=rarity_default, key=f"rarity_in_form_{suffix}") 
        color_in = st.text_input("5. é¢œè‰² (ä¾‹å¦‚: ç´«)", value=color_default, key=f"color_in_form_{suffix}") 
        
        price_in = st.number_input("6. ä»·æ ¼ (Â¥)", min_value=0.0, step=10.0, key=f"price_in_form_{suffix}")
        quantity_in = st.number_input("7. æ•°é‡ (å¼ )", min_value=1, step=1, key=f"quantity_in_form_{suffix}")
        
        date_in = st.date_input(
            "8. å½•å…¥æ—¥æœŸ", 
            value=st.session_state['last_entry_date'],
            key=f"date_in_form_{suffix}"
        )

        st.divider()
        st.write("ğŸ–¼ï¸ å¡ç‰Œå›¾ç‰‡ (å¯ä¿®æ­£)")

        image_url_input = st.text_input("è¾“å…¥å›¾ç‰‡ç½‘å€ (URL)", value=img_url_default, key=f"image_url_input_form_{suffix}")
        final_image_path = image_url_input if image_url_input else None
        
        if final_image_path:
            try:
                st.image(final_image_path, caption="é¢„è§ˆ", use_container_width=True)
            except: 
                st.warning("æ— æ³•åŠ è½½è¯¥é“¾æ¥çš„å›¾ç‰‡ã€‚")

        submitted = st.form_submit_button("æäº¤å½•å…¥", type="primary")

    if submitted:
        if name_in:
            with st.spinner("ğŸš€ æ•°æ®å³æ—¶ä¿å­˜ä¸­..."):
                add_card(name_in, card_number_in, set_in, price_in, quantity_in, rarity_in, color_in, date_in, final_image_path)
            
            st.session_state['last_entry_date'] = date_in

            st.session_state['scrape_result'] = {}
            st.session_state['form_key_suffix'] += 1
            
            st.session_state['submission_successful'] = True
            st.session_state['submitted_card_name'] = name_in
            
            st.rerun() 
        else:
            st.error("å¡ç‰Œåç§°ä¸èƒ½ä¸ºç©ºï¼")

# --- ä¸»é¡µé¢ ---
st.title("ğŸ“ˆ å¡ç‰Œå†å²ä¸ä»·æ ¼åˆ†æ Pro")

# æ£€æŸ¥å¹¶æ˜¾ç¤ºä¿å­˜ç»“æœ
if st.session_state.get('autosave_successful'):
    if "âŒ" in st.session_state['autosave_message']:
        st.error(st.session_state['autosave_message'])
    else:
        st.success(st.session_state['autosave_message'])
        
    st.session_state['autosave_successful'] = False
    st.session_state['autosave_message'] = ""
    
# æ£€æŸ¥å¹¶æ˜¾ç¤ºå½•å…¥ç»“æœ
if st.session_state.get('submission_successful'):
    card_name = st.session_state.get('submitted_card_name', 'ä¸€å¼ å¡ç‰Œ')
    st.success(f"âœ… å·²æˆåŠŸå½•å…¥: **{card_name}**ã€‚é¡µé¢å·²è‡ªåŠ¨è¿”å›é¡¶éƒ¨ã€‚")
    st.session_state['submission_successful'] = False
    st.session_state['submitted_card_name'] = ""

df = load_data() 

if df.empty:
    st.info("ğŸ‘‹ æ¬¢è¿ï¼è¯·åœ¨å·¦ä¾§å½•å…¥ä½ çš„ç¬¬ä¸€å¼ å¡ç‰Œæ•°æ®ã€‚")
else:
    # é¢„å¤„ç†
    df['date_dt'] = pd.to_datetime(df['date'], errors='coerce')
    df['image_url'] = df['image_url'].fillna('')
    df['rarity'] = df['rarity'].fillna('') 
    df['color'] = df['color'].fillna('') 
    df['card_set'] = df['card_set'].fillna('') 
    df['card_number'] = df['card_number'].fillna('') 
    
    # ã€ä¿®æ­£åŒºåŸŸã€‘ï¼šç¡®ä¿ price å’Œ quantity çš„ç±»å‹ä¸€è‡´æ€§
    df['price'] = pd.to_numeric(df['price'], errors='coerce').fillna(0.0).astype(float)
    df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce').fillna(1).astype(int) 
    
    df = df.dropna(subset=['date_dt']) 
    
    # --- ğŸ” å¤šç»´åº¦ç­›é€‰ ---
    st.markdown("### ğŸ” å¤šç»´åº¦ç­›é€‰")
    
    col_s1, col_s2, col_s3 = st.columns(3) 
    
    with col_s1: 
        search_name = st.text_input("æœç´¢ åç§°/ç¼–å·/ID", help="æ”¯æŒæ¨¡ç³Šæœç´¢") 
    with col_s2: 
        search_set = st.text_input("æœç´¢ ç³»åˆ—/ç‰ˆæœ¬")
    with col_s3: 
        date_range = st.date_input(
            "æœç´¢ æ—¶é—´èŒƒå›´", 
            value=[], 
            help="è¯·é€‰æ‹©å¼€å§‹å’Œç»“æŸæ—¥æœŸ"
        )

    # --- ç­›é€‰é€»è¾‘ (ç”¨äºç¼–è¾‘å’Œåˆ†æ) ---
    filtered_df = df.copy()
    
    if search_name:
        cleaned_search_name = normalize_text_for_fuzzy_search(search_name)
        search_target = (
            filtered_df['card_name'].astype(str).apply(normalize_text_for_fuzzy_search) + 
            filtered_df['card_number'].astype(str).apply(normalize_text_for_fuzzy_search) + 
            filtered_df['id'].astype(str).apply(normalize_text_for_fuzzy_search)
        )
        search_condition = search_target.str.contains(cleaned_search_name, case=False, na=False)
        filtered_df = filtered_df[search_condition]
        
    if search_set:
        filtered_df = filtered_df[filtered_df['card_set'].str.contains(search_set, case=False, na=False)]
    if len(date_range) == 2:
        # ç¡®ä¿ date_range åŒ…å«ä¸¤ä¸ªæ—¥æœŸ
        filtered_df = filtered_df[(filtered_df['date_dt'].dt.date >= date_range[0]) & (filtered_df['date_dt'].dt.date <= date_range[1])]

    
    # --- ğŸ“ æ•°æ®ç¼–è¾‘åŒºåŸŸ ---
    
    st.markdown("### ğŸ“ æ•°æ®ç¼–è¾‘ï¼ˆç¼–è¾‘åéœ€æ‰‹åŠ¨ä¿å­˜ï¼‰")
    st.caption("âœ¨ **ä¿®æ”¹/åˆ é™¤**ï¼šåŒå‡»å•å…ƒæ ¼ä¿®æ”¹å†…å®¹ï¼Œæˆ–é€‰ä¸­è¡ŒåæŒ‰ `Delete` é”®åˆ é™¤ã€‚å®Œæˆåè¯·ç‚¹å‡»ä¸‹æ–¹çš„ **ä¿å­˜ä¿®æ”¹** æŒ‰é’®ã€‚")
    
    # å‡†å¤‡ç”¨äºå±•ç¤ºå’Œç¼–è¾‘çš„ DataFrame (ä½¿ç”¨ç­›é€‰ç»“æœ)
    display_df = filtered_df.drop(columns=['date_dt'], errors='ignore').copy()

    # 1. æ ¸å¿ƒä¿®æ­£ï¼šç¡®ä¿æ—¥æœŸæ˜¯å…¼å®¹ st.data_editor çš„ datetime.date ç±»å‹
    # å°†åŸå§‹çš„æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆæˆ–å¯¹è±¡ï¼‰è½¬æ¢ä¸º datetime å¯¹è±¡
    date_series = pd.to_datetime(display_df['date'], errors='coerce')
    
    # å¡«å…… NaT å€¼ï¼šä½¿ç”¨ä»Šå¤©æ—¥æœŸæ¥æ›¿æ¢ä»»ä½•æ— æ•ˆæˆ–ç¼ºå¤±çš„æ—¥æœŸ
    date_series = date_series.fillna(datetime.now())
    
    # è½¬æ¢ä¸º Python åŸç”Ÿçš„ date å¯¹è±¡ï¼Œä»¥æœ€å¤§åŒ–ä¸ st.column_config.DateColumn çš„å…¼å®¹æ€§
    display_df['date'] = date_series.dt.date

    # æ ¸å¿ƒæ’åºé€»è¾‘ï¼šæ ¹æ® ID ä»å¤§åˆ°å°ï¼ˆæœ€æ–°çš„åœ¨æœ€ä¸Šé¢ï¼‰è¿›è¡Œåˆå§‹æ’åº
    display_df = display_df.sort_values(by='id', ascending=False)
    
    # å¼ºåˆ¶é‡ç½®ç´¢å¼• (è¿™ä¸€æ­¥æ˜¯å¿…è¦çš„ï¼Œä½† Streamlit çš„ data_editor ä¼šè‡ªè¡Œå¤„ç†ç´¢å¼•æ˜ å°„)
    display_df = display_df.reset_index(drop=True) 

    
    FINAL_DISPLAY_COLUMNS = ['date', 'card_number', 'card_name', 'card_set', 'price', 'quantity', 'rarity', 'color', 'image_url']
    
    # ç¡®ä¿ ID åˆ—åœ¨æœ€å‰é¢
    display_df = display_df[['id'] + FINAL_DISPLAY_COLUMNS]

    if display_df.empty:
        st.info("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆç­›é€‰æ¡ä»¶çš„æ•°æ®å¯ä¾›ç¼–è¾‘ã€‚")
        # ç¡®ä¿ session state ä¸­å­˜åœ¨ data_editor é”®ï¼Œé˜²æ­¢åç»­é€»è¾‘æŠ¥é”™
        if "data_editor" not in st.session_state:
            st.session_state["data_editor"] = {"edited_rows": {}, "deleted_rows": []}
        edited_df = display_df.copy() # å¦‚æœæ˜¯ç©ºçš„ï¼Œedited_df ä¹Ÿæ˜¯ç©ºçš„
    else:
        column_config_dict = {
            "id": st.column_config.Column("ID", disabled=True, width=50), 
            "date": st.column_config.DateColumn("å½•å…¥æ—¶é—´", width=80), 
            "card_number": st.column_config.Column("ç¼–å·", width=70),
            "card_name": st.column_config.Column("å¡å", width=200), 
            "card_set": st.column_config.Column("ç³»åˆ—", width=100), 
            # ä½¿ç”¨ NumberColumn ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            "price": st.column_config.NumberColumn("ä»·æ ¼ (Â¥)", format="Â¥%d", width=70),
            "quantity": st.column_config.NumberColumn("æ•°é‡ (å¼ )", format="%d", width=50),
            "rarity": st.column_config.Column("ç­‰çº§", width=50), 
            "color": st.column_config.Column("é¢œè‰²", width=50), 
            "image_url": st.column_config.ImageColumn("å¡å›¾", width=50),
        }
        
        # Line 422: st.data_editor call
        edited_df = st.data_editor(
            display_df, 
            key="data_editor", # æ ¸å¿ƒï¼šå°†ç¼–è¾‘çŠ¶æ€å­˜å…¥ session state
            hide_index=True,
            column_order=['id'] + FINAL_DISPLAY_COLUMNS,
            column_config=column_config_dict,
            num_rows="dynamic", # å…è®¸ç”¨æˆ·æ·»åŠ æ–°è¡Œ
            selection_mode="multi-row",
        )

    # ã€æ ¸å¿ƒä¿å­˜é€»è¾‘ã€‘
    editor_state = st.session_state.get("data_editor", {})
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¼–è¾‘å˜åŠ¨ã€åˆ é™¤æ“ä½œæˆ–æ–°å¢è¡Œ
    if editor_state.get("edited_rows") or editor_state.get("deleted_rows") or (len(edited_df) > len(display_df)):
        st.warning("âš ï¸ æ•°æ®ä¿®æ”¹ã€æ–°å¢æˆ–åˆ é™¤æ“ä½œå·²æ£€æµ‹åˆ°ã€‚è¯·ç‚¹å‡» **ä¿å­˜ä¿®æ”¹** æŒ‰é’®ï¼")
        
        # ç”±äºæˆ‘ä»¬ä½¿ç”¨å…¨é‡ä¿å­˜ï¼Œæˆ‘ä»¬ç›´æ¥å°† data_editor è¿”å›çš„ DataFrame ä¼ é€’ç»™ä¿å­˜å‡½æ•°
        final_df_to_save = edited_df.copy() 
        
        if st.button("ğŸ’¾ ç¡®è®¤å¹¶ä¿å­˜æ‰€æœ‰ä¿®æ”¹", type="primary"):
            with st.spinner("ğŸš€ æ•°æ®å³æ—¶ä¿å­˜ä¸­..."):
                # è°ƒç”¨å…¨é‡ä¿å­˜å‡½æ•°
                update_data_and_save(final_df_to_save)
            
            # å¿…é¡»è°ƒç”¨ rerun æ¥åˆ·æ–°æ•°æ®ï¼Œæ¸…é™¤ data_editor çš„çŠ¶æ€ï¼Œå¹¶æ˜¾ç¤ºä¿å­˜æˆåŠŸçš„æ¶ˆæ¯
            st.rerun()

    
    st.divider()
    
    # --- ğŸ“Š å•å¡æ·±åº¦åˆ†æé¢æ¿ (ä½¿ç”¨ç­›é€‰ç»“æœ) ---
    st.markdown("### ğŸ“Š å•å¡æ·±åº¦åˆ†æ")
    
    analysis_df = filtered_df.copy() 

    if analysis_df.empty:
        st.warning("æ— ç­›é€‰ç»“æœã€‚")
    else:
        analysis_df['unique_label'] = analysis_df.apply(
            lambda x: f"{x['card_name']} [{x['card_number']}] ({x['card_set']}) - {x['rarity']}/{x['color']}", 
            axis=1
        )
        
        unique_variants = analysis_df['unique_label'].unique()
        selected_variant = st.selectbox("è¯·é€‰æ‹©è¦åˆ†æçš„å…·ä½“å¡ç‰Œ:", unique_variants)
        
        target_df = analysis_df[analysis_df['unique_label'] == selected_variant].sort_values("date_dt")
        
        col_img, col_stat, col_chart = st.columns([1, 1, 2])
        
        with col_img:
            st.caption("å¡ç‰Œå¿«ç…§ (æœ€è¿‘ä¸€ç¬”)")
            latest_img = target_df.iloc[-1]['image_url'] if not target_df.empty else None
            if latest_img:
                try:
                    st.image(latest_img, use_container_width=True) 
                except:
                    st.error("å›¾ç‰‡åŠ è½½å¤±è´¥")
            else:
                st.empty()
                st.caption("æš‚æ— å›¾ç‰‡")

        with col_stat:
            st.caption("ä»·æ ¼ç»Ÿè®¡")
            if not target_df.empty:
                curr_price = target_df.iloc[-1]['price']
                total_quantity = target_df['quantity'].sum()
                avg_price = target_df['price'].mean()
                
                max_price = target_df['price'].max()
                # ç¡®ä¿åœ¨å–æ—¥æœŸæ—¶ï¼Œdfä¸æ˜¯ç©ºçš„ï¼Œä¸”æ—¥æœŸæ˜¯æœ‰æ•ˆçš„
                max_price_date = target_df[target_df['price'] == max_price]['date'].iloc[0] if not target_df[target_df['price'] == max_price].empty else "N/A"
                
                min_price = target_df['price'].min()
                min_price_date = target_df[target_df['price'] == min_price]['date'].iloc[0] if not target_df[target_df['price'] == min_price].empty else "N/A"

                c1, c2 = st.columns(2)
                c1.metric("ğŸ’° æœ€æ–°æˆäº¤", f"Â¥{curr_price:,.0f}")
                c2.metric("ğŸ“¦ æ€»åº“å­˜", f"{total_quantity:,} å¼ ")
                
                st.divider()
                
                c3, c4 = st.columns(2)
                c3.metric("ğŸ“ˆ å†å²æœ€é«˜", f"Â¥{max_price:,.0f}", f"äº {max_price_date} å½•å…¥")
                c4.metric("ğŸ“‰ å†å²æœ€ä½", f"Â¥{min_price:,.0f}", f"äº {min_price_date} å½•å…¥")
                
                st.metric("ğŸ“Š å¹³å‡ä»·æ ¼", f"Â¥{avg_price:,.2f}")
                
                st.caption(f"å…± {len(target_df)} æ¡è®°å½•")
            else:
                st.info("æ— æ•°æ®ç»Ÿè®¡ã€‚")


        with col_chart:
            st.caption("ä»·æ ¼èµ°åŠ¿å›¾")
            if len(target_df) > 1:
                st.line_chart(target_df, x="date_dt", y="price", color="#FF4B4B")
            else:
                st.info("éœ€è‡³å°‘ä¸¤æ¡è®°å½•ç»˜åˆ¶èµ°åŠ¿")
        
        # æœ€è¿‘10æ¬¡å½•å…¥è®°å½•è¡¨æ ¼
        if not target_df.empty:
            st.markdown("#### ğŸ•’ æœ€è¿‘10æ¬¡å½•å…¥è®°å½•")
            
            recent_10_df = target_df.sort_values("date_dt", ascending=False).head(10)
            
            recent_display = recent_10_df[['date', 'price', 'quantity']].copy()
            
            recent_display.rename(columns={
                'date': 'å½•å…¥æ—¥æœŸ',
                'price': 'ä»·æ ¼ (Â¥)',
                'quantity': 'æ•°é‡ (å¼ )'
            }, inplace=True)
            
            st.dataframe(
                recent_display, 
                hide_index=True, 
                use_container_width=True,
                column_config={
                    "ä»·æ ¼ (Â¥)": st.column_config.NumberColumn(format="Â¥%d"),
                    "æ•°é‡ (å¼ )": st.column_config.NumberColumn(format="%d")
                }
            )
    
    # --- ğŸ“¥ æ•°æ®å¯¼å‡º (ç”¨äºå¤‡ä»½æˆ–è¿ç§») ---
    st.divider()
    st.markdown("### ğŸ“¥ æ•°æ®å¯¼å‡º (ç”¨äºå¤‡ä»½æˆ–è¿ç§»)")
    if not df.empty:
        csv_data = df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
        st.download_button(
            label="ä¸‹è½½å®Œæ•´çš„å¡ç‰Œæ•°æ® (CSV)",
            data=csv_data,
            file_name='card_data_full_export.csv',
            mime='text/csv',
            help='ç‚¹å‡»ä¸‹è½½ Supabase ä¸­çš„æ‰€æœ‰æ•°æ®ï¼Œç”¨äºå¤‡ä»½ã€‚'
        )
