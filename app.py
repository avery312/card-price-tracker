import streamlit as st
import pandas as pd
from datetime import datetime
import requests
from bs4 import BeautifulSoup
import re 
import gspread 
import gspread_dataframe as gd
import numpy as np 
import time # ä¿æŒå¯¼å…¥ï¼Œå°½ç®¡åœ¨æœ€ç»ˆä»£ç ä¸­æœªä½¿ç”¨

# === é…ç½® ===
SHEET_NAME = "æ•°æ®è¡¨" 
# å®šä¹‰ Google Sheets å­—æ®µé¡ºåº
NEW_EXPECTED_COLUMNS = ['id', 'date', 'card_number', 'card_name', 'card_set', 'price', 'quantity', 'rarity', 'color', 'image_url']

# --- Streamlit Session State ---
if 'scrape_result' not in st.session_state:
    st.session_state['scrape_result'] = {}
    
def clear_all_data():
    st.session_state['scrape_result'] = {} 
    st.session_state['scrape_url_input'] = ""

# === è¾…åŠ©å‡½æ•°ï¼šæ¨¡ç³Šæœç´¢è§„èŒƒåŒ– ===
def normalize_text_for_fuzzy_search(text):
    """
    ç§»é™¤ç©ºæ ¼å’Œè¿å­—ç¬¦ï¼Œå¹¶è½¬æ¢ä¸ºå¤§å†™ï¼Œç”¨äºå¿½ç•¥æ ¼å¼çš„æ¨¡ç³Šæœç´¢åŒ¹é…ã€‚
    """
    if pd.isna(text):
        return ""
    cleaned = str(text).replace('-', '').replace(' ', '')
    return cleaned.upper()

# === Gspread æ•°æ®åº“å‡½æ•° ===

@st.cache_resource(ttl=None)
def connect_gspread():
    """ä½¿ç”¨ Streamlit Secrets å‡­è¯è¿æ¥åˆ° Google Sheets API (ç¼“å­˜è¿æ¥å¯¹è±¡)"""
    try:
        creds = {
            "type": st.secrets["gsheets"]["type"],
            "project_id": st.secrets["gsheets"]["project_id"],
            "private_key_id": st.secrets["gsheets"]["private_key_id"],
            "private_key": st.secrets["gsheets"]["private_key"],
            "client_email": st.secrets["gsheets"]["client_email"],
            "client_id": st.secrets["gsheets"]["client_id"],
            "auth_uri": st.secrets["gsheets"]["auth_uri"],
            "token_uri": st.secrets["gsheets"]["token_uri"],
            "auth_provider_x509_cert_url": st.secrets["gsheets"]["auth_provider_x509_cert_url"],
            "client_x509_cert_url": st.secrets["gsheets"]["client_x509_cert_url"],
            "universe_domain": st.secrets["gsheets"]["universe_domain"]
        }
        
        gc = gspread.service_account_from_dict(creds)
        spreadsheet_url = st.secrets["gsheets"]["spreadsheet_url"]
        
        # å…¼å®¹æ€§å¤„ç†ï¼šå»é™¤ URL ä¸­çš„ gid å‚æ•°
        base_url = spreadsheet_url.split('/edit')[0] 
        sh = gc.open_by_url(base_url)
        
        return sh
    except Exception as e:
        st.error(f"æ— æ³•è¿æ¥ Google Sheets APIã€‚è¯·æ£€æŸ¥ Secrets æ ¼å¼ã€æƒé™åŠ URLã€‚é”™è¯¯: {e}")
        return None

# ğŸ”‘ å…³é”®ï¼šç§»é™¤ @st.cache_data è£…é¥°å™¨ï¼Œå¼ºåˆ¶æ¯æ¬¡è„šæœ¬è¿è¡Œæ—¶éƒ½è¯»å–æœ€æ–°æ•°æ®
def load_data():
    """ä» Google Sheets è¯»å–æ‰€æœ‰æ•°æ® (æ— ç¼“å­˜ï¼Œå³æ—¶è¯»å–)"""
    sh = connect_gspread()
    if not sh:
        return pd.DataFrame(columns=NEW_EXPECTED_COLUMNS)
    
    try:
        worksheet = sh.worksheet(SHEET_NAME) 
        df = gd.get_as_dataframe(worksheet)
        
        if df.empty or not all(col in df.columns for col in NEW_EXPECTED_COLUMNS):
            # å°è¯•ä¿®å¤ç©ºè¡¨æ—¶çš„åˆ—å¤´é—®é¢˜
            if df.empty:
                return pd.DataFrame(columns=NEW_EXPECTED_COLUMNS)
            st.warning("Google Sheets åˆ—å¤´ç»“æ„ä¸ä»£ç é¢„æœŸä¸ç¬¦ã€‚")
            return pd.DataFrame(columns=NEW_EXPECTED_COLUMNS)

        # æ•°æ®æ¸…æ´—å’Œ ID ç¡®ä¿
        df = df.replace({np.nan: None}) # å°† NaN æ›¿æ¢ä¸º None
        df['id'] = pd.to_numeric(df['id'], errors='coerce').fillna(0).astype(int)
        
        # é‡æ–°ç”Ÿæˆ ID ä»¥ç¡®ä¿ä¸é‡å¤ï¼Œå¦‚æœå‘ç° ID é‡å¤æˆ–ä¸º 0
        if df['id'].duplicated().any() or (df['id'] == 0).any():
             # ä»…åœ¨éœ€è¦æ—¶æ‰é‡æ–°ç”Ÿæˆ IDï¼Œå¹¶ç¡®ä¿æ˜¯è¿ç»­çš„
             df.loc[:, 'id'] = range(1, len(df) + 1)
        
        # ç¡®ä¿åˆ—é¡ºåº
        df = df[NEW_EXPECTED_COLUMNS] 

        # æ ¹æ® ID é™åºæ’åºï¼Œç¡®ä¿æœ€æ–°è®°å½•åœ¨é¡¶éƒ¨
        return df.sort_values(by='id', ascending=False)
    except Exception as e:
        st.error(f"æ— æ³•è¯»å–å·¥ä½œè¡¨ '{SHEET_NAME}'ã€‚é”™è¯¯: {e}")
        return pd.DataFrame(columns=NEW_EXPECTED_COLUMNS)

# æ–°å¢/è¿½åŠ å¡ç‰Œ
def add_card(name, number, card_set, price, quantity, rarity, color, date, image_url=None):
    sh = connect_gspread()
    if not sh: return
    
    try:
        worksheet = sh.worksheet(SHEET_NAME)
        
        # ä¸ºäº†è·å–æ­£ç¡®çš„ max_idï¼Œæˆ‘ä»¬å¿…é¡»è¯»å–æœ€æ–°æ•°æ®ã€‚
        df = load_data() 
        
        try:
            max_id = pd.to_numeric(df['id'], errors='coerce').max()
            new_id = int(max_id + 1) if pd.notna(max_id) else 1
        except:
            new_id = 1
        
        # å‡†å¤‡è¦è¿½åŠ çš„è¡Œæ•°æ® (å¿…é¡»ä¸ NEW_EXPECTED_COLUMNS é¡ºåºä¸€è‡´)
        new_row = [
            new_id, 
            date.strftime('%Y-%m-%d'),
            number, 
            name, 
            card_set, 
            price, 
            quantity, 
            rarity,       
            color,        
            image_url if image_url else ""
        ]
        
        worksheet.append_row(new_row, value_input_option='USER_ENTERED')
        
    except Exception as e:
        st.error(f"è¿½åŠ æ•°æ®åˆ° Sheets å¤±è´¥ã€‚é”™è¯¯: {e}")

# åˆ é™¤å¡ç‰Œå‡½æ•°
def delete_card(card_id):
    sh = connect_gspread()
    if not sh: 
        st.error("æ— æ³•è¿æ¥ Google Sheetsã€‚")
        return
    
    try:
        worksheet = sh.worksheet(SHEET_NAME)
        # å¼ºåˆ¶è¯»å–æœ€æ–°æ•°æ®
        df = load_data() 
        
        # è¿‡æ»¤æ‰è¦åˆ é™¤çš„è¡Œ
        df_updated = df[df['id'] != card_id]
        
        # ç¡®ä¿åªä¿ç•™ NEW_EXPECTED_COLUMNS
        df_final = df_updated[NEW_EXPECTED_COLUMNS].replace({None: ''}) 
        
        # è¦†ç›–å·¥ä½œè¡¨
        gd.set_with_dataframe(worksheet, df_final, row=1, col=1, include_index=False, include_column_header=True)
        
        st.success(f"ID {card_id} è®°å½•å·²åˆ é™¤ï¼æ­£åœ¨åˆ·æ–°é¡µé¢...")
        st.rerun() 
        
    except Exception as e:
        st.error(f"åˆ é™¤æ•°æ®å¤±è´¥ã€‚é”™è¯¯: {e}")
        
# å¤„ç†æ•°æ®ç¼–è¾‘å™¨çš„å†…å®¹å¹¶ä¿å­˜åˆ° Google Sheets
def update_data_and_save(edited_df):
    sh = connect_gspread()
    if not sh: return
    
    try:
        worksheet = sh.worksheet(SHEET_NAME)
        
        # æ•°æ®ç±»å‹æ¸…ç†å’Œæ ¼å¼åŒ–
        edited_df['date'] = pd.to_datetime(edited_df['date'], errors='coerce').dt.strftime('%Y-%m-%d')
        edited_df['id'] = pd.to_numeric(edited_df['id'], errors='coerce').fillna(0).astype(int)
        edited_df['price'] = pd.to_numeric(edited_df['price'], errors='coerce').fillna(0)
        edited_df['quantity'] = pd.to_numeric(edited_df['quantity'], errors='coerce').fillna(0).astype(int)
        
        # ç¡®ä¿åˆ—é¡ºåºå¹¶å¤„ç†ç¼ºå¤±å€¼
        df_final = edited_df[NEW_EXPECTED_COLUMNS].fillna('')
        
        # è¦†ç›–å·¥ä½œè¡¨
        gd.set_with_dataframe(worksheet, df_final, row=1, col=1, include_index=False, include_column_header=True)
        
        st.success("æ•°æ®ä¿®æ”¹å·²è‡ªåŠ¨ä¿å­˜åˆ° Google è¡¨æ ¼ï¼")
    except Exception as e:
        st.error(f"ä¿å­˜ä¿®æ”¹å¤±è´¥ã€‚é”™è¯¯: {e}")


# ç½‘é¡µæŠ“å–å‡½æ•° 
def scrape_card_data(url):
    st.info(f"æ­£åœ¨å°è¯•ä» {url} æŠ“å–æ•°æ®...")
    if not url.startswith("http"):
        return {"error": "ç½‘å€æ ¼å¼ä¸æ­£ç¡®ã€‚"}
    
    try:
        
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, timeout=10, headers=headers)
        response.raise_for_status() 
        response.encoding = response.apparent_encoding
        soup = BeautifulSoup(response.content, 'html.parser')

        name_tag = soup.find(['h1', 'h2'], class_=re.compile(r'heading|title', re.I))
        full_title = name_tag.get_text(strip=True) if name_tag else ""
        
        if not full_title:
             return {"error": "æœªèƒ½æ‰¾åˆ°å¡ç‰Œåç§°æ ‡é¢˜ã€‚"}

        card_name = "N/A"; rarity = "N/A"; color = "N/A"; card_number = "N/A"; card_set = "" 
        temp_title = full_title 

        # 1. æå– rarity
        rarity_match = re.search(r'ã€(.+?)ã€‘', temp_title)
        if rarity_match:
            rarity = rarity_match.group(1).strip()
            temp_title = temp_title.replace(rarity_match.group(0), ' ').strip()
        
        # 2. æå– color
        color_match = re.search(r'ã€Š(.+?)ã€‹', temp_title)
        if color_match:
            color = color_match.group(1).strip()
            temp_title = temp_title.replace(color_match.group(0), ' ').strip()
        
        # 3. æå– card_number
        number_match = re.search(r'([A-Z0-9]{1,}\-\d{2,})', temp_title) 
        
        if number_match:
            card_number = number_match.group(1).strip()
            temp_title_without_number = temp_title[:number_match.start()] + temp_title[number_match.end():]
        else:
            temp_title_without_number = temp_title
        
        # 4. æå– card_set å’Œ card_name
        name_part = re.match(r'(.+?)[\s\[ã€]', temp_title_without_number.strip())
        if name_part:
            card_name = name_part.group(1).strip()
            card_set = temp_title_without_number[len(name_part.group(0)):].strip()
        else:
            card_name = temp_title_without_number.strip()
            card_set = ""
            
        card_set = re.sub(r'[\[\]ã€ã€]', '', card_set).strip()
        
        # --- 5. æå–å›¾ç‰‡é“¾æ¥ ---
        image_url = None
        
        og_image_tag = soup.find('meta', property='og:image')
        if og_image_tag:
            image_url = og_image_tag.get('content')
            
        if not image_url:
            image_tag = soup.find('img', {'alt': lambda x: x and 'ãƒ¡ã‚¤ãƒ³ç”»åƒ' in x}) or \
                        soup.find('img', {'alt': lambda x: x and card_name in x})
            
            if image_tag:
                image_url = image_tag.get('data-src') or image_tag.get('src') 
        
        if not image_url:
            st.warning("æœªèƒ½æ‰¾åˆ°å›¾ç‰‡é“¾æ¥ã€‚")

        return {
            "card_name": card_name, "card_number": card_number, "card_set": card_set,
            "card_rarity": rarity, "card_color": color, "image_url": image_url, "error": None
        }

    except requests.exceptions.RequestException as e:
        return {"error": f"ç½‘ç»œé”™è¯¯æˆ–æ— æ³•è®¿é—®: {e}"}
    except Exception as e:
        return {"error": f"è§£æé”™è¯¯: {e}"}

    
# === ç•Œé¢å¸ƒå±€ ===
st.set_page_config(page_title="å¡ç‰Œè¡Œæƒ…åˆ†æPro", page_icon="ğŸ“ˆ", layout="wide")


# --- ä¾§è¾¹æ ï¼šå½•å…¥ ---
with st.sidebar:
    st.header("ğŸŒ ç½‘é¡µè‡ªåŠ¨å¡«å……")
    
    # å°† key ç§»åŠ¨åˆ° session state ä¹‹å¤–ä»¥é¿å…å†²çª
    scrape_url = st.text_input("è¾“å…¥å¡ç‰Œè¯¦æƒ…é¡µç½‘å€:", key='scrape_url_input') 
    
    col_scrape_btn, col_clear_btn = st.columns(2)
    
    with col_scrape_btn:
        if st.button("ä¸€é”®æŠ“å–å¹¶å¡«å……", type="secondary"):
            if not scrape_url:
                 st.warning("è¯·è¾“å…¥ç½‘å€ã€‚")
            else:
                st.session_state['scrape_result'] = scrape_card_data(scrape_url)
                if st.session_state['scrape_result']['error']:
                    st.error(st.session_state['scrape_result']['error'])
                else:
                    st.success("æ•°æ®æŠ“å–å®Œæˆã€‚")
                 
    with col_clear_btn:
        # ä½¿ç”¨ on_click è§¦å‘å‡½æ•°
        st.button("ä¸€é”®æ¸…é™¤å½•å…¥å†…å®¹", type="primary", on_click=clear_all_data)

    st.divider()
    st.header("ğŸ“ æ‰‹åŠ¨å½•å…¥/ä¿®æ­£")
    
    # é¢„å¡«å……æŠ“å–ç»“æœ
    res = st.session_state['scrape_result']
    name_default = res.get('card_name', "")
    number_default = res.get('card_number', "")
    set_default = res.get('card_set', "")
    rarity_default = res.get('card_rarity', "") 
    color_default = res.get('card_color', "") 
    img_url_default = res.get('image_url', "")

    # ğŸ”‘ ä½¿ç”¨ st.form ç¡®ä¿è¾“å…¥å­—æ®µçŠ¶æ€å’Œæäº¤æ“ä½œçš„åŸå­æ€§
    with st.form(key="manual_entry_form"):
        # å½•å…¥å­—æ®µ
        card_number_in = st.text_input("1. å¡ç‰Œç¼–å·", value=number_default, key="card_number_in")
        name_in = st.text_input("2. å¡ç‰Œåç§° (å¿…å¡«)", value=name_default, key="name_in")
        set_in = st.text_input("3. ç³»åˆ—/ç‰ˆæœ¬", value=set_default, key="set_in") 
        rarity_in = st.text_input("4. ç­‰çº§ (Rarity)", value=rarity_default, key="rarity_in") 
        color_in = st.text_input("5. é¢œè‰² (ä¾‹å¦‚: ç´«)", value=color_default, key="color_in") 
        
        price_in = st.number_input("6. ä»·æ ¼ (Â¥)", min_value=0.0, step=10.0, key="price_in")
        quantity_in = st.number_input("7. æ•°é‡ (å¼ )", min_value=1, step=1, key="quantity_in")
        
        date_in = st.date_input("8. å½•å…¥æ—¥æœŸ", datetime.now(), key="date_in")

        st.divider()
        st.write("ğŸ–¼ï¸ å¡ç‰Œå›¾ç‰‡ (å¯ä¿®æ­£)")

        image_url_input = st.text_input("è¾“å…¥å›¾ç‰‡ç½‘å€ (URL)", value=img_url_default, key="image_url_input_form")
        final_image_path = image_url_input if image_url_input else None
        
        if final_image_path:
            try:
                st.image(final_image_path, caption="é¢„è§ˆ", use_container_width=True)
            except: 
                st.warning("æ— æ³•åŠ è½½è¯¥é“¾æ¥çš„å›¾ç‰‡ã€‚")

        # ä½¿ç”¨ st.form_submit_button
        submitted = st.form_submit_button("æäº¤å½•å…¥", type="primary")

    if submitted:
        if name_in:
            with st.spinner("ğŸš€ æ•°æ®å³æ—¶ä¿å­˜ä¸­..."):
                add_card(name_in, card_number_in, set_in, price_in, quantity_in, rarity_in, color_in, date_in, final_image_path)
            
            st.session_state['scrape_result'] = {}
            st.success(f"å·²å½•å…¥: {name_in}")
            # å¼ºåˆ¶é‡æ–°æ‰§è¡Œè„šæœ¬
            st.rerun()
        else:
            st.error("å¡ç‰Œåç§°ä¸èƒ½ä¸ºç©ºï¼")

# --- ä¸»é¡µé¢ ---
st.title("ğŸ“ˆ å¡ç‰Œå†å²ä¸ä»·æ ¼åˆ†æ Pro")

# ğŸ”‘ æ¯æ¬¡è„šæœ¬è¿è¡Œæ—¶éƒ½ä¼šæ‰§è¡Œï¼Œå¹¶ä» Google Sheets è¯»å–æœ€æ–°æ•°æ®
df = load_data()

if df.empty:
    st.info("ğŸ‘‹ æ¬¢è¿ï¼è¯·åœ¨å·¦ä¾§å½•å…¥ä½ çš„ç¬¬ä¸€å¼ å¡ç‰Œæ•°æ®ã€‚")
else:
    # é¢„å¤„ç†
    df['date_dt'] = pd.to_datetime(df['date'], errors='coerce')
    df['image_url'] = df['image_url'].fillna('')
    df['rarity'] = df['rarity'].fillna('') 
    df['color'] = df['color'].fillna('') 
    df['card_set'] = df['card_set'].fillna('') 
    df['card_number'] = df['card_number'].fillna('') 
    df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce').fillna(1).astype(int) 
    df = df.dropna(subset=['date_dt']) 
    
    # --- ğŸ” å¤šç»´åº¦ç­›é€‰ ---
    st.markdown("### ğŸ” å¤šç»´åº¦ç­›é€‰")
    col_s1, col_s2, col_s3 = st.columns(3) 
    with col_s1: search_name = st.text_input("æœç´¢ åç§°/ç¼–å·/ID", help="æ”¯æŒæ¨¡ç³Šæœç´¢ï¼Œä¾‹å¦‚è¾“å…¥ 'P 113' ä¹Ÿèƒ½åŒ¹é… 'P-113' æˆ–åŒ…å« 'P113' çš„å¡ç‰Œåç§°") 
    with col_s2: search_set = st.text_input("æœç´¢ ç³»åˆ—/ç‰ˆæœ¬")
    with col_s3: date_range = st.date_input("æœç´¢ æ—¶é—´èŒƒå›´", value=[], help="è¯·é€‰æ‹©å¼€å§‹å’Œç»“æŸæ—¥æœŸ")

    # ç­›é€‰é€»è¾‘
    filtered_df = df.copy()
    if search_name:
        cleaned_search_name = normalize_text_for_fuzzy_search(search_name)
        
        search_target = (
            filtered_df['card_name'].astype(str).apply(normalize_text_for_fuzzy_search) + 
            filtered_df['card_number'].astype(str).apply(normalize_text_for_fuzzy_search) + 
            filtered_df['id'].astype(str).apply(normalize_text_for_fuzzy_search)
        )
        
        search_condition = search_target.str.contains(cleaned_search_name, case=False, na=False)
        
        filtered_df = filtered_df[search_condition]
        
    if search_set:
        filtered_df = filtered_df[filtered_df['card_set'].str.contains(search_set, case=False, na=False)]
    if len(date_range) == 2:
        filtered_df = filtered_df[(filtered_df['date_dt'].dt.date >= date_range[0]) & (filtered_df['date_dt'].dt.date <= date_range[1])]

    # å‡†å¤‡ç”¨äºå±•ç¤ºå’Œç¼–è¾‘çš„ DataFrame
    display_df = filtered_df.drop(columns=['date_dt'], errors='ignore')

    # å¼ºåˆ¶å°† 'date' åˆ—ä»å­—ç¬¦ä¸²è½¬æ¢ä¸º datetime å¯¹è±¡
    display_df['date'] = pd.to_datetime(display_df['date'], errors='coerce') 

    st.markdown("### ğŸ“ æ•°æ®ç¼–è¾‘ï¼ˆåŒå‡»å•å…ƒæ ¼ä¿®æ”¹ï¼‰")
    
    # å®šä¹‰æœ€ç»ˆå‘ˆç°çš„åˆ—é¡ºåº
    FINAL_DISPLAY_COLUMNS = ['date', 'card_number', 'card_name', 'card_set', 'price', 'quantity', 'rarity', 'color', 'image_url']
    
    # ç¡®ä¿ display_df åŒ…å« 'id'
    display_df = display_df[['id'] + FINAL_DISPLAY_COLUMNS]
    
    # é…ç½®åˆ—æ˜¾ç¤ºåç§°å’Œæ ¼å¼ 
    column_config_dict = {
        "id": st.column_config.Column("ID", disabled=True), 
        "date": st.column_config.DateColumn("å½•å…¥æ—¶é—´"), 
        "card_number": "ç¼–å·",
        "card_name": "å¡å",
        "card_set": "ç³»åˆ—",
        "price": st.column_config.NumberColumn("ä»·æ ¼ (Â¥)", format="Â¥%d"),
        "quantity": st.column_config.NumberColumn("æ•°é‡ (å¼ )", format="%d"),
        "rarity": "ç­‰çº§", 
        "color": "é¢œè‰²",
        "image_url": st.column_config.ImageColumn("å¡å›¾", width="small"),
    }
    
    # ä½¿ç”¨ st.data_editor å®ç°è¡¨æ ¼ç¼–è¾‘åŠŸèƒ½
    edited_df = st.data_editor(
        display_df,
        key="data_editor",
        use_container_width=True, 
        hide_index=True,
        column_order=['id'] + FINAL_DISPLAY_COLUMNS,
        column_config=column_config_dict,
    )

    # æ£€æŸ¥æ˜¯å¦æœ‰ç¼–è¾‘å˜åŠ¨
    if st.session_state["data_editor"]["edited_rows"] or st.session_state["data_editor"]["deleted_rows"]:
        st.caption("æ£€æµ‹åˆ°æ•°æ®ä¿®æ”¹ï¼Œè¯·ç‚¹å‡» **ä¿å­˜ä¿®æ”¹** æŒ‰é’®ã€‚")
        
        final_df_to_save = edited_df
        
        if st.button("ğŸ’¾ ç¡®è®¤å¹¶ä¿å­˜æ‰€æœ‰ä¿®æ”¹", type="primary"):
            update_data_and_save(final_df_to_save)
            st.rerun()

    
    st.divider()
    
    # --- âŒ æ‰‹åŠ¨åˆ é™¤è®°å½• ---
    st.markdown("### âŒ æ‰‹åŠ¨åˆ é™¤è®°å½•")
    
    if not filtered_df.empty:
        delete_options = filtered_df.sort_values(by='date', ascending=False).apply(
            lambda x: f"ID {x['id']} | {x['date']} | {x['card_name']} [{x['card_number']}] ({x['card_set']}) - {x['rarity']}/{x['color']} @ Â¥{x['price']:,.0f}", 
            axis=1
        )
        
        col_del_select, col_del_btn = st.columns([3, 1])
        
        with col_del_select:
            if not delete_options.empty:
                selected_delete_option = st.selectbox("é€‰æ‹©è¦åˆ é™¤çš„è®°å½•:", delete_options)
            else:
                selected_delete_option = None
        
        if selected_delete_option:
            delete_id_match = re.search(r'ID (\d+)\s*\|', selected_delete_option)
            card_id_to_delete = int(delete_id_match.group(1)) if delete_id_match else None
            
            with col_del_btn:
                 st.markdown("<br>", unsafe_allow_html=True)
                 if st.button("ğŸ”´ ç¡®è®¤åˆ é™¤æ‰€é€‰è®°å½•", type="secondary"):
                     if card_id_to_delete:
                         delete_card(card_id_to_delete)
                     else:
                         st.error("æ— æ³•è¯†åˆ«è¦åˆ é™¤çš„è®°å½• IDã€‚")
    else:
        st.info("æ²¡æœ‰å¯åˆ é™¤çš„è®°å½•ã€‚")
        
    st.divider()

    # --- ğŸ“Š å•å¡æ·±åº¦åˆ†æé¢æ¿ ---
    st.markdown("### ğŸ“Š å•å¡æ·±åº¦åˆ†æ")
    
    analysis_df = filtered_df.copy() 

    if analysis_df.empty:
        st.warning("æ— ç­›é€‰ç»“æœã€‚")
    else:
        analysis_df['unique_label'] = analysis_df.apply(
            lambda x: f"{x['card_name']} [{x['card_number']}] ({x['card_set']}) - {x['rarity']}/{x['color']}", 
            axis=1
        )
        
        unique_variants = analysis_df['unique_label'].unique()
        selected_variant = st.selectbox("è¯·é€‰æ‹©è¦åˆ†æçš„å…·ä½“å¡ç‰Œ:", unique_variants)
        
        target_df = analysis_df[analysis_df['unique_label'] == selected_variant].sort_values("date_dt")
        
        col_img, col_stat, col_chart = st.columns([1, 1, 2])
        
        with col_img:
            st.caption("å¡ç‰Œå¿«ç…§ (æœ€è¿‘ä¸€ç¬”)")
            latest_img = target_df.iloc[-1]['image_url']
            if latest_img:
                try:
                    st.image(latest_img, use_container_width=True) 
                except:
                    st.error("å›¾ç‰‡åŠ è½½å¤±è´¥")
            else:
                st.empty()
                st.caption("æš‚æ— å›¾ç‰‡")

        with col_stat:
            st.caption("ä»·æ ¼ç»Ÿè®¡")
            if not target_df.empty:
                curr_price = target_df.iloc[-1]['price']
                total_quantity = target_df['quantity'].sum()
                
                max_price = target_df['price'].max()
                max_price_date = target_df[target_df['price'] == max_price]['date'].iloc[0]
                
                min_price = target_df['price'].min()
                min_price_date = target_df[target_df['price'] == min_price]['date'].iloc[0]

                st.metric("æœ€è¿‘æˆäº¤ä»·", f"Â¥{curr_price:,.0f}")
                
                st.markdown(f"**ğŸ“ˆ å†å²æœ€é«˜**ï¼šÂ¥{max_price:,.0f} (äº **{max_price_date}** å½•å…¥)")
                st.markdown(f"**ğŸ“‰ å†å²æœ€ä½**ï¼šÂ¥{min_price:,.0f} (äº **{min_price_date}** å½•å…¥)")
                
                st.metric("ğŸ’° å¹³å‡ä»·æ ¼", f"Â¥{target_df['price'].mean():,.2f}")
                st.metric("ğŸ“¦ æ€»åº“å­˜æ•°é‡", f"{total_quantity:,} å¼ ")
                st.write(f"å…± {len(target_df)} æ¡è®°å½•")
            else:
                st.info("æ— æ•°æ®ç»Ÿè®¡ã€‚")


        with col_chart:
            st.caption("ä»·æ ¼èµ°åŠ¿å›¾")
            if len(target_df) > 1:
                st.line_chart(target_df, x="date", y="price", color="#FF4B4B")
            else:
                st.info("éœ€è‡³å°‘ä¸¤æ¡è®°å½•ç»˜åˆ¶èµ°åŠ¿")

    # =========================================================================
    # ğŸ”‘ ç§»åŠ¨åˆ°æœ€åº•éƒ¨ï¼šæ•°æ®å¯¼å‡ºåŠŸèƒ½
    # =========================================================================
    st.divider()
    st.markdown("### ğŸ“¥ æ•°æ®å¯¼å‡º (ç”¨äºå¤‡ä»½æˆ–è¿ç§»)")
    
    # ç¡®ä¿ä½¿ç”¨å®Œæ•´çš„ DataFrame df è¿›è¡Œå¯¼å‡ºï¼Œè€Œä¸æ˜¯ç­›é€‰åçš„ filtered_df
    if not df.empty:
        csv_data = df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
        st.download_button(
            label="ä¸‹è½½å®Œæ•´çš„å¡ç‰Œæ•°æ® (CSV)",
            data=csv_data,
            file_name='card_data_full_export.csv',
            mime='text/csv',
            help="ç‚¹å‡»ä¸‹è½½ Google è¡¨æ ¼ä¸­çš„æ‰€æœ‰æ•°æ®ï¼Œç”¨äºå¤‡ä»½ã€‚"
        )
