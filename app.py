import streamlit as st
import pandas as pd
# æ˜ç¡®å¯¼å…¥ datetime å’Œ date å¯¹è±¡
from datetime import datetime, date 
import requests
from bs4 import BeautifulSoup
import re 
import numpy as np 
# å¯¼å…¥ Supabase å®¢æˆ·ç«¯åº“
from supabase import create_client, Client 
import time 

# === é…ç½® ===
SUPABASE_TABLE_NAME = "cards" 
NEW_EXPECTED_COLUMNS = ['id', 'date', 'card_number', 'card_name', 'card_set', 'price', 'quantity', 'rarity', 'color', 'image_url']

# --- Streamlit Session State ---
if 'scrape_result' not in st.session_state:
    st.session_state['scrape_result'] = {}
if 'form_key_suffix' not in st.session_state: 
    st.session_state['form_key_suffix'] = 0

if 'submission_successful' not in st.session_state: 
    st.session_state['submission_successful'] = False
if 'submitted_card_name' not in st.session_state: 
    st.session_state['submitted_card_name'] = "" 

if 'last_entry_date' not in st.session_state:
    st.session_state['last_entry_date'] = datetime.now().date() 
    
if 'autosave_successful' not in st.session_state:
    st.session_state['autosave_successful'] = False
if 'autosave_message' not in st.session_state:
    st.session_state['autosave_message'] = ""

if 'date_range_input' not in st.session_state:
    st.session_state['date_range_input'] = [] 
if 'search_name_input' not in st.session_state:
    st.session_state['search_name_input'] = ""
if 'search_set_input' not in st.session_state:
    st.session_state['search_set_input'] = ""


def clear_all_data():
    """æ¸…é™¤æ‰€æœ‰å½•å…¥ç›¸å…³ Session Stateã€‚"""
    st.session_state['scrape_result'] = {} 
    st.session_state['form_key_suffix'] += 1 
    st.session_state['last_entry_date'] = datetime.now().date() 

def clear_search_filters_action():
    """æ¸…é™¤æ‰€æœ‰ç­›é€‰ç›¸å…³çš„ Session State å˜é‡ã€‚ç”¨äº on_click å›è°ƒã€‚"""
    st.session_state["search_name_input"] = ""
    st.session_state["search_set_input"] = ""
    st.session_state["date_range_input"] = [] 


# === è¾…åŠ©å‡½æ•°ï¼šæ¨¡ç³Šæœç´¢è§„èŒƒåŒ– ===
def normalize_text_for_fuzzy_search(text):
    if pd.isna(text):
        return ""
    cleaned = str(text).replace('-', '').replace(' ', '')
    return cleaned.upper()

# === Supabase æ•°æ®åº“å‡½æ•° ===

@st.cache_resource(ttl=None)
def connect_supabase() -> Client:
    """ä½¿ç”¨ Streamlit Secrets å‡­è¯è¿æ¥åˆ° Supabase æ•°æ®åº“ (è¿æ¥å¯¹è±¡ç¼“å­˜)"""
    try:
        url: str = st.secrets["supabase"]["URL"]
        key: str = st.secrets["supabase"]["KEY"]
        supabase: Client = create_client(url, key)
        return supabase
    except Exception as e:
        st.error(f"æ— æ³•è¿æ¥ Supabase æ•°æ®åº“ã€‚è¯·æ£€æŸ¥ secrets.toml é…ç½®ã€‚é”™è¯¯: {e}")
        return None

def load_data():
    """ä» Supabase è¯»å–æ‰€æœ‰æ•°æ® (æ¯æ¬¡è„šæœ¬è¿è¡Œæ—¶éƒ½å¼ºåˆ¶è¯»å–)"""
    supabase = connect_supabase()
    if not supabase:
        return pd.DataFrame(columns=NEW_EXPECTED_COLUMNS)
    
    try:
        # ç›´æ¥è¯»å–æ•°æ®
        response = supabase.table(SUPABASE_TABLE_NAME).select("*").order("date", desc=True).execute()
        
        df = pd.DataFrame(response.data)
        
        if df.empty:
             return pd.DataFrame(columns=NEW_EXPECTED_COLUMNS)

        df = df.replace({np.nan: None}) 
        df['id'] = pd.to_numeric(df['id'], errors='coerce').fillna(0).astype(int)
        
        df = df[NEW_EXPECTED_COLUMNS] 

        return df
    except Exception as e:
        st.error(f"æ— æ³•ä» Supabase è¯»å–æ•°æ®ã€‚é”™è¯¯: {e}")
        return pd.DataFrame(columns=NEW_EXPECTED_COLUMNS)

# æ–°å¢/è¿½åŠ å¡ç‰Œ
def add_card(name, number, card_set, price, quantity, rarity, color, date, image_url=None):
    supabase = connect_supabase()
    if not supabase: return
    
    try:
        # 1. ç›´æ¥æŸ¥è¯¢ Supabase è·å–æœ€å¤§çš„ ID 
        response = supabase.table(SUPABASE_TABLE_NAME).select("id").order("id", desc=True).limit(1).execute()
        
        max_id = 0
        if response.data and response.data[0] and 'id' in response.data[0]:
            # æ‰¾åˆ°å½“å‰æœ€å¤§çš„ ID
            max_id = response.data[0]['id']
            
        new_id = int(max_id + 1) if pd.notna(max_id) else 1
        
        # 2. å‡†å¤‡è¦æ’å…¥çš„å­—å…¸æ•°æ®
        new_row_data = {
            "id": new_id,
            "date": date.strftime('%Y-%m-%d'),
            "card_number": number,
            "card_name": name,
            "card_set": card_set,
            "price": price,
            "quantity": quantity,
            "rarity": rarity,
            "color": color,
            "image_url": image_url if image_url else ""
        }
        
        # 3. æ‰§è¡Œæ’å…¥æ“ä½œ
        supabase.table(SUPABASE_TABLE_NAME).insert(new_row_data).execute()
        
    except Exception as e:
        st.error(f"è¿½åŠ æ•°æ®åˆ° Supabase å¤±è´¥ã€‚é”™è¯¯: {e}")

# å¢é‡ä¿å­˜å‡½æ•°ï¼Œç”¨äºè‡ªåŠ¨ä¿å­˜
def save_incremental_changes(displayed_df: pd.DataFrame, editor_state: dict):
    """
    æ ¹æ® data_editor çš„çŠ¶æ€ï¼Œå¯¹ Supabase è¿›è¡Œç²¾ç¡®çš„ UPSERT å’Œ DELETE æ“ä½œã€‚
    """
    supabase = connect_supabase()
    if not supabase: return
    
    deleted_count = 0
    updated_count = 0
    
    try:
        # 1. å¤„ç†åˆ é™¤æ“ä½œ (DELETE)
        deleted_indices = editor_state.get("deleted_rows", [])
        if deleted_indices:
            # æ ¹æ® 0-based ç´¢å¼•ä»æ˜¾ç¤ºçš„ DataFrame ä¸­è·å–è¦åˆ é™¤çš„è®°å½•çš„ ID
            ids_to_delete = displayed_df.iloc[deleted_indices]['id'].tolist()
            
            if ids_to_delete:
                deleted_count = len(ids_to_delete)
                supabase.table(SUPABASE_TABLE_NAME).delete().in_('id', ids_to_delete).execute()

        # 2. å¤„ç†ä¿®æ”¹æ“ä½œ (UPSERT/UPDATE)
        edited_rows = editor_state.get("edited_rows", {})
        if edited_rows:
            data_to_upsert = []
            
            for filtered_index, changes in edited_rows.items():
                # è·³è¿‡å·²åˆ é™¤çš„è¡Œ
                if filtered_index in deleted_indices:
                    continue
                
                # ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ
                if filtered_index >= len(displayed_df):
                    continue
                    
                row_id = displayed_df.iloc[filtered_index]['id']
                update_data = {'id': int(row_id)}
                
                # è·å–åŸå§‹æ—¥æœŸ (Timestamp å¯¹è±¡)
                original_date_ts = displayed_df.iloc[filtered_index]['date']
                
                # è®¾ç½®å›é€€æ—¥æœŸ
                initial_date_str = datetime.now().strftime('%Y-%m-%d')
                if pd.notna(original_date_ts):
                    try:
                        initial_date_str = original_date_ts.strftime('%Y-%m-%d')
                    except:
                        pass
                
                update_data['date'] = initial_date_str 
                
                # éå†ä¿®æ”¹
                for col, value in changes.items():
                    if col == 'date':
                        final_date_str_edit = None
                        # å¤„ç†å¯èƒ½çš„è¾“å…¥ç±»å‹ï¼šå­—ç¬¦ä¸²æˆ–Timestamp
                        if value:
                            if isinstance(value, str):
                                final_date_str_edit = value
                            elif isinstance(value, (datetime, pd.Timestamp)):
                                final_date_str_edit = value.strftime('%Y-%m-%d')
                            elif isinstance(value, date):
                                final_date_str_edit = value.strftime('%Y-%m-%d')
                        
                        if final_date_str_edit:
                            update_data[col] = final_date_str_edit 

                    elif col in ['price']:
                        update_data[col] = float(value) if pd.notna(value) else 0.0
                    elif col in ['quantity']:
                        update_data[col] = int(value) if pd.notna(value) else 0
                    else:
                        update_data[col] = str(value) if pd.notna(value) else ""
                        
                data_to_upsert.append(update_data)
            
            if data_to_upsert:
                updated_count = len(data_to_upsert)
                supabase.table(SUPABASE_TABLE_NAME).upsert(data_to_upsert).execute()

        if deleted_count > 0 or updated_count > 0:
            msg = f"âœ… å·²è‡ªåŠ¨ä¿å­˜ï¼šæ›´æ–° {updated_count} æ¡ï¼Œåˆ é™¤ {deleted_count} æ¡ã€‚"
            st.session_state['autosave_successful'] = True
            st.session_state['autosave_message'] = msg
        
    except Exception as e:
        st.session_state['autosave_successful'] = True
        st.session_state['autosave_message'] = f"âŒ è‡ªåŠ¨ä¿å­˜å¤±è´¥ã€‚é”™è¯¯: {e}"


# ç½‘é¡µæŠ“å–å‡½æ•°
def scrape_card_data(url):
    st.info(f"æ­£åœ¨å°è¯•ä» {url} æŠ“å–æ•°æ®...")
    if not url.startswith("http"):
        return {"error": "ç½‘å€æ ¼å¼ä¸æ­£ç¡®ã€‚"}
    
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, timeout=10, headers=headers)
        response.raise_for_status() 
        response.encoding = response.apparent_encoding
        soup = BeautifulSoup(response.content, 'html.parser')

        name_tag = soup.find(['h1', 'h2'], class_=re.compile(r'heading|title', re.I))
        full_title = name_tag.get_text(strip=True) if name_tag else ""
        
        if not full_title:
             return {"error": "æœªèƒ½æ‰¾åˆ°å¡ç‰Œåç§°æ ‡é¢˜ã€‚"}

        card_name = "N/A"; rarity = "N/A"; color = "N/A"; card_number = "N/A"; card_set = "" 
        temp_title = full_title 

        collection_tag = soup.find(lambda tag: tag.name in ['p', 'div', 'span', 'li'] and 'â‰ªåéŒ²â‰«' in tag.get_text())
        is_collection_found = False
        if collection_tag:
            collection_text = collection_tag.get_text(strip=True)
            set_match = re.search(r'â‰ªåéŒ²â‰«\s*(.*?)(\w+[\s\w]+?ã€[A-Z0-9\-\_]+?\ã€‘)', collection_text, re.DOTALL)
            if set_match:
                card_set = set_match.group(2).strip()
                is_collection_found = True
            else:
                set_match_fallback = re.search(r'â‰ªåéŒ²â‰«\s*(.+?)(?:\s*ã€‚|\s*ã€|\s*<|$)|\s+(.+?)(?:\s*ã€‚|\s*ã€|\s*<|$)', collection_text, re.DOTALL)
                if set_match_fallback:
                    card_set = (set_match_fallback.group(1) or set_match_fallback.group(2)).strip()
                    is_collection_found = True
            if is_collection_found:
                card_set = re.sub(r'^[\[ï¼ˆã€Œã€]', '', card_set).strip()
                card_set = re.sub(r'[\]ï¼‰ã€ã€]$', '', card_set).strip()

        rarity_match = re.search(r'ã€(.+?)ã€‘', temp_title)
        if rarity_match:
            rarity = rarity_match.group(1).strip()
            temp_title = temp_title.replace(rarity_match.group(0), ' ').strip()
        
        color_match = re.search(r'ã€Š(.+?)ã€‹', temp_title)
        if color_match:
            color = color_match.group(1).strip()
            temp_title = temp_title.replace(color_match.group(0), ' ').strip()
        
        number_match = re.search(r'([A-Z0-9]{1,}\-\d{2,})', temp_title) 
        if number_match:
            card_number = number_match.group(1).strip()
            temp_title_without_number = temp_title[:number_match.start()] + temp_title[number_match.end():]
        else:
            temp_title_without_number = temp_title
        
        if not is_collection_found:
            name_part = re.match(r'(.+?)[\s\[ã€]', temp_title_without_number.strip())
            if name_part:
                card_name = name_part.group(1).strip()
                card_set = temp_title_without_number[len(name_part.group(0)):].strip()
            else:
                card_name = temp_title_without_number.strip()
                card_set = ""
            card_set = re.sub(r'[\[\]ã€ã€]', '', card_set).strip()
        else:
            card_name = temp_title_without_number.strip()

        image_url = None
        og_image_tag = soup.find('meta', property='og:image')
        if og_image_tag:
            image_url = og_image_tag.get('content')
        if not image_url:
            image_tag = soup.find('img', {'alt': lambda x: x and 'ãƒ¡ã‚¤ãƒ³ç”»åƒ' in x}) or \
                        soup.find('img', {'alt': lambda x: x and card_name in x})
            if image_tag:
                image_url = image_tag.get('data-src') or image_tag.get('src') 
        
        return {
            "card_name": card_name, "card_number": card_number, "card_set": card_set,
            "card_rarity": rarity, "card_color": color, "image_url": image_url, "error": None
        }
    except Exception as e:
        return {"error": f"è§£æé”™è¯¯: {e}"}

# === ç•Œé¢å¸ƒå±€ ===
st.set_page_config(page_title="å¡ç‰Œè¡Œæƒ…åˆ†æPro", page_icon="ğŸ“ˆ", layout="wide")

suffix = str(st.session_state['form_key_suffix']) 

# --- ä¾§è¾¹æ ï¼šå½•å…¥ ---
with st.sidebar:
    if st.session_state.get('submission_successful'):
        card_name = st.session_state.get('submitted_card_name', 'ä¸€å¼ å¡ç‰Œ')
        st.success(f"âœ… **{card_name}** å½•å…¥æˆåŠŸï¼", icon="ğŸ‰") 
        
    st.header("ğŸŒ ç½‘é¡µè‡ªåŠ¨å¡«å……")
    scrape_url = st.text_input("è¾“å…¥å¡ç‰Œè¯¦æƒ…é¡µç½‘å€:", key=f'scrape_url_input_{suffix}') 
    
    col_scrape_btn, col_clear_btn = st.columns(2)
    with col_scrape_btn:
        if st.button("ä¸€é”®æŠ“å–å¹¶å¡«å……", type="secondary", key=f"scrape_btn_{suffix}"):
            if not scrape_url: st.warning("è¯·è¾“å…¥ç½‘å€ã€‚")
            else:
                st.session_state['scrape_result'] = scrape_card_data(scrape_url)
                if st.session_state['scrape_result']['error']: st.error(st.session_state['scrape_result']['error'])
                else: st.success("æ•°æ®æŠ“å–å®Œæˆã€‚")
                st.session_state['form_key_suffix'] += 1
                st.rerun() 
    with col_clear_btn:
        if st.button("ä¸€é”®æ¸…é™¤å½•å…¥å†…å®¹", type="primary", key=f"clear_btn_{suffix}", on_click=clear_all_data):
            st.rerun() 

    st.divider()
    st.header("ğŸ“ æ‰‹åŠ¨å½•å…¥/ä¿®æ­£")
    
    res = st.session_state['scrape_result']
    name_default = res.get('card_name', "")
    number_default = res.get('card_number', "")
    set_default = res.get('card_set', "")
    rarity_default = res.get('card_rarity', "") 
    color_default = res.get('card_color', "") 
    img_url_default = res.get('image_url', "")

    with st.form(key=f"manual_entry_form_{suffix}"):
        card_number_in = st.text_input("1. å¡ç‰Œç¼–å·", value=number_default, key=f"card_number_in_form_{suffix}")
        name_in = st.text_input("2. å¡ç‰Œåç§° (å¿…å¡«)", value=name_default, key=f"name_in_form_{suffix}")
        set_in = st.text_input("3. ç³»åˆ—/ç‰ˆæœ¬", value=set_default, key=f"set_in_form_{suffix}") 
        rarity_in = st.text_input("4. ç­‰çº§ (Rarity)", value=rarity_default, key=f"rarity_in_form_{suffix}") 
        color_in = st.text_input("5. é¢œè‰² (ä¾‹å¦‚: ç´«)", value=color_default, key=f"color_in_form_{suffix}") 
        price_in = st.number_input("6. ä»·æ ¼ (Â¥)", min_value=0.0, step=10.0, key=f"price_in_form_{suffix}")
        quantity_in = st.number_input("7. æ•°é‡ (å¼ )", min_value=1, step=1, key=f"quantity_in_form_{suffix}")
        date_in = st.date_input("8. å½•å…¥æ—¥æœŸ", value=st.session_state['last_entry_date'], key=f"date_in_form_{suffix}")

        st.divider()
        st.write("ğŸ–¼ï¸ å¡ç‰Œå›¾ç‰‡ (å¯ä¿®æ­£)")
        image_url_input = st.text_input("è¾“å…¥å›¾ç‰‡ç½‘å€ (URL)", value=img_url_default, key=f"image_url_input_form_{suffix}")
        final_image_path = image_url_input if image_url_input else None
        if final_image_path:
            try: st.image(final_image_path, caption="é¢„è§ˆ", use_container_width=True)
            except: st.warning("æ— æ³•åŠ è½½è¯¥é“¾æ¥çš„å›¾ç‰‡ã€‚")

        submitted = st.form_submit_button("æäº¤å½•å…¥", type="primary")

    if submitted:
        if name_in:
            with st.spinner("ğŸš€ æ•°æ®å³æ—¶ä¿å­˜ä¸­..."):
                add_card(name_in, card_number_in, set_in, price_in, quantity_in, rarity_in, color_in, date_in, final_image_path)
            st.session_state['last_entry_date'] = date_in
            st.session_state['scrape_result'] = {}
            st.session_state['form_key_suffix'] += 1
            st.session_state['submission_successful'] = True
            st.session_state['submitted_card_name'] = name_in
            st.rerun() 
        else:
            st.error("å¡ç‰Œåç§°ä¸èƒ½ä¸ºç©ºï¼")

# --- ä¸»é¡µé¢ ---
st.title("ğŸ“ˆ å¡ç‰Œå†å²ä¸ä»·æ ¼åˆ†æ Pro")

if st.session_state.get('autosave_successful'):
    if "âŒ" in st.session_state['autosave_message']:
        st.error(st.session_state['autosave_message'])
    else:
        st.success(st.session_state['autosave_message'])
    st.session_state['autosave_successful'] = False
    st.session_state['autosave_message'] = ""
    
if st.session_state.get('submission_successful'):
    card_name = st.session_state.get('submitted_card_name', 'ä¸€å¼ å¡ç‰Œ')
    st.success(f"âœ… å·²æˆåŠŸå½•å…¥: **{card_name}**ã€‚é¡µé¢å·²è‡ªåŠ¨è¿”å›é¡¶éƒ¨ã€‚")
    st.session_state['submission_successful'] = False
    st.session_state['submitted_card_name'] = ""

df = load_data() 

if df.empty:
    st.info("ğŸ‘‹ æ¬¢è¿ï¼è¯·åœ¨å·¦ä¾§å½•å…¥ä½ çš„ç¬¬ä¸€å¼ å¡ç‰Œæ•°æ®ã€‚")
else:
    df['date_dt'] = pd.to_datetime(df['date'], errors='coerce')
    df['image_url'] = df['image_url'].fillna('')
    df['rarity'] = df['rarity'].fillna('') 
    df['color'] = df['color'].fillna('') 
    df['card_set'] = df['card_set'].fillna('') 
    df['card_number'] = df['card_number'].fillna('') 
    df['price'] = pd.to_numeric(df['price'], errors='coerce').fillna(0.0).astype(float)
    df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce').fillna(1).astype(int) 
    df = df.dropna(subset=['date_dt']) 
    
    st.markdown("### ğŸ” å¤šç»´åº¦ç­›é€‰")
    col_s1, col_s2, col_s3, col_s4 = st.columns([3, 3, 3, 1]) 
    
    with col_s1: search_name = st.text_input("æœç´¢ åç§°/ç¼–å·/ID", value=st.session_state["search_name_input"], help="æ”¯æŒæ¨¡ç³Šæœç´¢", key="search_name_input") 
    with col_s2: search_set = st.text_input("æœç´¢ ç³»åˆ—/ç‰ˆæœ¬", value=st.session_state["search_set_input"], key="search_set_input")
    with col_s3: date_range = st.date_input("æœç´¢ æ—¶é—´èŒƒå›´", value=st.session_state.get("date_range_input", []), help="è¯·é€‰æ‹©å¼€å§‹å’Œç»“æŸæ—¥æœŸ", key="date_range_input")
    with col_s4: 
        st.write(" ") 
        st.button("æ¸…ç©ºç­›é€‰", key="clear_filters_btn", use_container_width=True, on_click=clear_search_filters_action) 

    filtered_df = df.copy()
    if search_name:
        cleaned_search_name = normalize_text_for_fuzzy_search(search_name)
        search_target = (
            filtered_df['card_name'].astype(str).apply(normalize_text_for_fuzzy_search) + 
            filtered_df['card_number'].astype(str).apply(normalize_text_for_fuzzy_search) + 
            filtered_df['id'].astype(str).apply(normalize_text_for_fuzzy_search)
        )
        search_condition = search_target.str.contains(cleaned_search_name, case=False, na=False)
        filtered_df = filtered_df[search_condition]
        
    if search_set:
        filtered_df = filtered_df[filtered_df['card_set'].str.contains(search_set, case=False, na=False)]
    if len(date_range) == 2:
        filtered_df = filtered_df[(filtered_df['date_dt'].dt.date >= date_range[0]) & (filtered_df['date_dt'].dt.date <= date_range[1])]

    # --- ğŸ“ æ•°æ®ç¼–è¾‘åŒºåŸŸ ---
    st.markdown("### ğŸ“ æ•°æ®ç¼–è¾‘ï¼ˆè‡ªåŠ¨å¢é‡ä¿å­˜æ¨¡å¼ï¼‰")
    st.caption("âœ¨ **è‡ªåŠ¨å¢é‡ä¿å­˜**ï¼šä¿®æ”¹å†…å®¹åç‚¹å‡»è¡¨æ ¼å¤–ä»»æ„å¤„ï¼Œç³»ç»Ÿè‡ªåŠ¨ä¿å­˜ã€‚")
    st.caption("âœ… **æ•´è¡Œåˆ é™¤**ï¼šè¡¨æ ¼**æœ€å·¦ä¾§**æ˜¯**è¡Œé€‰æ‹©å¤é€‰æ¡†**ã€‚å‹¾é€‰åæŒ‰ **`Delete`** é”®åˆ é™¤ã€‚")
    
    # æ ¸å¿ƒä¿®å¤ 1: å‡†å¤‡æ•°æ®ï¼Œç¡®ä¿ date åˆ—æ˜¯ datetime64[ns] ç±»å‹
    display_df = filtered_df.drop(columns=['date_dt'], errors='ignore')
    
    # å°†æ—¥æœŸåˆ—å¼ºåˆ¶è½¬æ¢ä¸º datetime64[ns]ï¼Œè¿™å¯¹ Streamlit DateColumn æœ€å®‰å…¨
    display_df['date'] = pd.to_datetime(display_df['date'], errors='coerce')
    
    display_df = display_df.sort_values(by='id', ascending=False)
    display_df = display_df.reset_index(drop=True) 
    
    FINAL_DISPLAY_COLUMNS = ['date', 'card_number', 'card_name', 'card_set', 'price', 'quantity', 'rarity', 'color', 'image_url']
    display_df = display_df[['id'] + FINAL_DISPLAY_COLUMNS]

    if display_df.empty:
        st.info("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆç­›é€‰æ¡ä»¶çš„æ•°æ®å¯ä¾›ç¼–è¾‘ã€‚")
        if "data_editor" not in st.session_state:
            st.session_state["data_editor"] = {"edited_rows": {}, "deleted_rows": []}
    else:
        column_config_dict = {
            "id": st.column_config.Column("ID", disabled=True, width=50), 
            "date": st.column_config.DateColumn("å½•å…¥æ—¶é—´", width=80), # DateColumn ä¼šè‡ªåŠ¨å¤„ç† datetime64[ns]
            "card_number": st.column_config.Column("ç¼–å·", width=70),
            "card_name": st.column_config.Column("å¡å", width=200), 
            "card_set": st.column_config.Column("ç³»åˆ—", width=100), 
            "price": st.column_config.NumberColumn("ä»·æ ¼ (Â¥)", format="Â¥%d", width=70),
            "quantity": st.column_config.NumberColumn("æ•°é‡ (å¼ )", format="%d", width=50),
            "rarity": st.column_config.Column("ç­‰çº§", width=50), 
            "color": st.column_config.Column("é¢œè‰²", width=50), 
            "image_url": st.column_config.ImageColumn("å¡å›¾", width=50),
        }
        
        # ç§»é™¤ selection_mode="multi-row" ä»¥å…¼å®¹æ—§ç‰ˆæœ¬
        edited_df = st.data_editor(
            display_df, 
            key="data_editor",
            hide_index=True,
            column_order=['id'] + FINAL_DISPLAY_COLUMNS,
            column_config=column_config_dict,
            num_rows="dynamic",
            use_container_width=True 
        )

    editor_state = st.session_state.get("data_editor")
    if editor_state and (editor_state.get("edited_rows") or editor_state.get("deleted_rows")):
        st.info("ğŸ”„ æ£€æµ‹åˆ°ä¿®æ”¹ï¼Œæ­£åœ¨è‡ªåŠ¨å¢é‡ä¿å­˜...")
        with st.spinner("ğŸš€ æ•°æ®å¢é‡è‡ªåŠ¨ä¿å­˜ä¸­..."):
            save_incremental_changes(display_df, editor_state)
        st.rerun()

    st.divider()
    st.markdown("### ğŸ“Š å•å¡æ·±åº¦åˆ†æ")
    analysis_df = filtered_df.copy() 
    if analysis_df.empty:
        st.warning("æ— ç­›é€‰ç»“æœã€‚")
    else:
        analysis_df['unique_label'] = analysis_df.apply(lambda x: f"{x['card_name']} [{x['card_number']}] ({x['card_set']}) - {x['rarity']}/{x['color']}", axis=1)
        unique_variants = analysis_df['unique_label'].unique()
        selected_variant = st.selectbox("è¯·é€‰æ‹©è¦åˆ†æçš„å…·ä½“å¡ç‰Œ:", unique_variants)
        target_df = analysis_df[analysis_df['unique_label'] == selected_variant].sort_values("date_dt")
        
        col_img, col_stat, col_chart = st.columns([1, 1, 2])
        with col_img:
            st.caption("å¡ç‰Œå¿«ç…§ (æœ€è¿‘ä¸€ç¬”)")
            latest_img = target_df.iloc[-1]['image_url'] if not target_df.empty else None
            if latest_img:
                try: st.image(latest_img, use_container_width=True) 
                except: st.error("å›¾ç‰‡åŠ è½½å¤±è´¥")
            else:
                st.empty(); st.caption("æš‚æ— å›¾ç‰‡")

        with col_stat:
            st.caption("ä»·æ ¼ç»Ÿè®¡")
            if not target_df.empty:
                curr_price = target_df.iloc[-1]['price']
                total_quantity = target_df['quantity'].sum()
                avg_price = target_df['price'].mean()
                max_price = target_df['price'].max()
                max_price_date = target_df[target_df['price'] == max_price]['date'].iloc[0] if not target_df[target_df['price'] == max_price].empty else "N/A"
                min_price = target_df['price'].min()
                min_price_date = target_df[target_df['price'] == min_price]['date'].iloc[0] if not target_df[target_df['price'] == min_price].empty else "N/A"

                c1, c2 = st.columns(2)
                c1.metric("ğŸ’° æœ€æ–°æˆäº¤", f"Â¥{curr_price:,.0f}")
                c2.metric("ğŸ“¦ æ€»åº“å­˜", f"{total_quantity:,} å¼ ")
                st.divider()
                c3, c4 = st.columns(2)
                c3.metric("ğŸ“ˆ å†å²æœ€é«˜", f"Â¥{max_price:,.0f}", f"äº {max_price_date} å½•å…¥")
                c4.metric("ğŸ“‰ å†å²æœ€ä½", f"Â¥{min_price:,.0f}", f"äº {min_price_date} å½•å…¥")
                st.metric("ğŸ“Š å¹³å‡ä»·æ ¼", f"Â¥{avg_price:,.2f}")
                st.caption(f"å…± {len(target_df)} æ¡è®°å½•")
            else:
                st.info("æ— æ•°æ®ç»Ÿè®¡ã€‚")

        with col_chart:
            st.caption("ä»·æ ¼èµ°åŠ¿å›¾")
            if len(target_df) > 1:
                st.line_chart(target_df, x="date_dt", y="price", color="#FF4B4B")
            else:
                st.info("éœ€è‡³å°‘ä¸¤æ¡è®°å½•ç»˜åˆ¶èµ°åŠ¿")
        
        if not target_df.empty:
            st.markdown("#### ğŸ•’ æœ€è¿‘10æ¬¡å½•å…¥è®°å½•")
            recent_10_df = target_df.sort_values("date_dt", ascending=False).head(10)
            recent_display = recent_10_df[['date', 'price', 'quantity']].copy()
            recent_display.rename(columns={'date': 'å½•å…¥æ—¥æœŸ', 'price': 'ä»·æ ¼ (Â¥)', 'quantity': 'æ•°é‡ (å¼ )'}, inplace=True)
            st.dataframe(recent_display, hide_index=True, use_container_width=True, column_config={"ä»·æ ¼ (Â¥)": st.column_config.NumberColumn(format="Â¥%d"), "æ•°é‡ (å¼ )": st.column_config.NumberColumn(format="%d")})
    
    st.divider()
    st.markdown("### ğŸ“¥ æ•°æ®å¯¼å‡º (ç”¨äºå¤‡ä»½æˆ–è¿ç§»)")
    if not df.empty:
        csv_data = df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
        st.download_button(label="ä¸‹è½½å®Œæ•´çš„å¡ç‰Œæ•°æ® (CSV)", data=csv_data, file_name='card_data_full_export.csv', mime='text/csv')
