import streamlit as st
import pandas as pd
from datetime import datetime
import requests
from bs4 import BeautifulSoup
import re 
# æ›¿æ¢ä¸º gspread åŠå…¶è¾…åŠ©åº“
import gspread 
# ä¿®æ­£å¯¼å…¥æ–¹å¼ï¼šæ”¹ä¸ºå¯¼å…¥æ•´ä¸ªåº“å¹¶ä½¿ç”¨åˆ«å
import gspread_dataframe as gd

# === é…ç½® ===
# æ³¨æ„: å¦‚æœæ‚¨çš„ Google Sheets æ ‡ç­¾é¡µåç§°ä¸æ˜¯â€œæ•°æ®è¡¨â€ï¼Œè¯·åœ¨æ­¤å¤„ä¿®æ”¹!
SHEET_NAME = "æ•°æ®è¡¨" 
YUYU_TEI_BASE_IMAGE_URL = 'https://card.yuyu-tei.jp/opc/front/' 

# === Gspread æ•°æ®åº“å‡½æ•° (ä½¿ç”¨æ ‡å‡† gspread åº“) ===

@st.cache_resource(ttl=None)
def connect_gspread():
    """ä½¿ç”¨ Streamlit Secrets å‡­è¯è¿æ¥åˆ° Google Sheets API"""
    try:
        # ä½¿ç”¨ st.secrets ç›´æ¥åŠ è½½ TOML é…ç½®ä¸­çš„å‡­è¯
        # ç¡®ä¿ Secrets TOML æ–‡ä»¶ä¸­çš„é”®åä¸€è‡´
        creds = {
            "type": st.secrets["gsheets"]["type"],
            "project_id": st.secrets["gsheets"]["project_id"],
            "private_key_id": st.secrets["gsheets"]["private_key_id"],
            "private_key": st.secrets["gsheets"]["private_key"],
            "client_email": st.secrets["gsheets"]["client_email"],
            "client_id": st.secrets["gsheets"]["client_id"],
            "auth_uri": st.secrets["gsheets"]["auth_uri"],
            "token_uri": st.secrets["gsheets"]["token_uri"],
            "auth_provider_x509_cert_url": st.secrets["gsheets"]["auth_provider_x509_cert_url"],
            "client_x509_cert_url": st.secrets["gsheets"]["client_x509_cert_url"],
            "universe_domain": st.secrets["gsheets"]["universe_domain"]
        }
        
        gc = gspread.service_account_from_dict(creds)
        spreadsheet_url = st.secrets["gsheets"]["spreadsheet_url"]
        
        # ç§»é™¤ URL ä¸­çš„ gid å‚æ•°ï¼Œç¡®ä¿ open_by_url æ­£ç¡®æ‰“å¼€æ•´ä¸ªæ–‡æ¡£
        base_url = spreadsheet_url.split('/edit')[0] 
        sh = gc.open_by_url(base_url)
        
        return sh
    except Exception as e:
        st.error(f"æ— æ³•è¿æ¥ Google Sheets APIã€‚è¯·æ£€æŸ¥ Secrets æ ¼å¼å’Œæƒé™ã€‚é”™è¯¯: {e}")
        return None

@st.cache_data(ttl=3600)
def load_data():
    """ä» Google Sheets è¯»å–æ‰€æœ‰æ•°æ®"""
    sh = connect_gspread()
    # å¦‚æœè¿æ¥å¤±è´¥ï¼Œè¿”å›ç©ºæ•°æ®æ¡†
    if not sh:
        return pd.DataFrame(columns=['id', 'card_name', 'card_number', 'card_set', 'rarity', 'price', 'quantity', 'date', 'image_url'])
    
    try:
        # è·å–æŒ‡å®šåç§°çš„å·¥ä½œè¡¨
        worksheet = sh.worksheet(SHEET_NAME) 
        
        # ä½¿ç”¨ gspread-dataframe è¯»å–ä¸º DataFrame 
        df = gd.get_dataframe(worksheet)
        
        # ç¡®ä¿åˆ—å¤´åŒ¹é…
        expected_columns = ['id', 'card_name', 'card_number', 'card_set', 'rarity', 'price', 'quantity', 'date', 'image_url']
        if df.empty or not all(col in df.columns for col in expected_columns):
            # å¦‚æœè¡¨æ ¼ä¸ºç©ºæˆ–ç»“æ„ä¸æ­£ç¡®ï¼Œè¿”å›ä¸€ä¸ªå¸¦æœ‰é¢„æœŸåˆ—çš„ç©ºæ•°æ®æ¡†
            return pd.DataFrame(columns=expected_columns)

        return df.sort_values(by='date', ascending=False)
    except Exception as e:
        st.error(f"æ— æ³•è¯»å–å·¥ä½œè¡¨ '{SHEET_NAME}'ã€‚è¯·ç¡®ä¿å·¥ä½œè¡¨åç§°æ­£ç¡®ã€‚é”™è¯¯: {e}")
        return pd.DataFrame(columns=['id', 'card_name', 'card_number', 'card_set', 'rarity', 'price', 'quantity', 'date', 'image_url'])


# æ›´æ–°åçš„ add_card å‡½æ•°ï¼šç›´æ¥å‘ Sheets è¿½åŠ è¡Œ
def add_card(name, number, card_set, rarity, price, quantity, date, image_url=None):
    sh = connect_gspread()
    if not sh: return
    
    try:
        worksheet = sh.worksheet(SHEET_NAME)
        # è·å–æœ€æ–°æ•°æ®ä»¥è®¡ç®— ID
        df = load_data() 
        
        # ç”Ÿæˆæ–°çš„å”¯ä¸€ ID
        try:
            max_id = pd.to_numeric(df['id'], errors='coerce').max()
            new_id = int(max_id + 1) if pd.notna(max_id) else 1
        except:
            new_id = 1
        
        # å‡†å¤‡è¦è¿½åŠ çš„è¡Œæ•°æ® (å¿…é¡»ä¸è¡¨æ ¼åˆ—é¡ºåºä¸€è‡´)
        new_row = [
            new_id, 
            name, 
            number, 
            card_set, 
            rarity, 
            price, 
            quantity, 
            date.strftime('%Y-%m-%d'), # æ ¼å¼åŒ–æ—¥æœŸ
            image_url if image_url else ""
        ]
        
        # ä½¿ç”¨ gspread çš„ append_row æ–¹æ³•è¿½åŠ 
        worksheet.append_row(new_row, value_input_option='USER_ENTERED')
        
        # æ¸…é™¤ç¼“å­˜
        st.cache_data.clear()
        st.cache_resource.clear()
        
    except Exception as e:
        st.error(f"è¿½åŠ æ•°æ®åˆ° Sheets å¤±è´¥ã€‚é”™è¯¯: {e}")

# åˆ é™¤å¡ç‰Œå‡½æ•°ï¼šé€šè¿‡é‡å†™æ•´ä¸ªæ•°æ®æ¡†å®ç°æ’é™¤ (æœ€å®‰å…¨çš„æ–¹æ³•)
def delete_card(card_id):
    sh = connect_gspread()
    if not sh: return
    
    try:
        worksheet = sh.worksheet(SHEET_NAME)
        df = load_data()
        
        # è¿‡æ»¤æ‰è¦åˆ é™¤çš„è¡Œ
        df_updated = df[pd.to_numeric(df['id'], errors='coerce') != card_id]
        
        # ç¡®ä¿åªä¿ç•™éœ€è¦çš„åˆ—
        columns_to_keep = ['id', 'card_name', 'card_number', 'card_set', 'rarity', 'price', 'quantity', 'date', 'image_url']
        df_final = df_updated[columns_to_keep]
        
        # è¦†ç›–å·¥ä½œè¡¨
        gd.set_with_dataframe(worksheet, df_final, row=1, col=1, include_index=False, include_column_header=True)
        
        st.cache_data.clear()
        st.cache_resource.clear()
        
    except Exception as e:
        st.error(f"åˆ é™¤æ•°æ®å¤±è´¥ã€‚é”™è¯¯: {e}")
        
# ç½‘é¡µæŠ“å–å‡½æ•° (ä¿æŒä¸å˜)
def scrape_card_data(url):
    st.info(f"æ­£åœ¨å°è¯•ä» {url} æŠ“å–æ•°æ®...")
    if not url.startswith("http"):
        return {"error": "ç½‘å€æ ¼å¼ä¸æ­£ç¡®ï¼Œå¿…é¡»ä»¥ http æˆ– https å¼€å¤´ã€‚"}
    
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status() 
        response.encoding = 'EUC-JP'
        soup = BeautifulSoup(response.content, 'html.parser')

        # --- 1. æå– ä¸»æ ‡é¢˜è¡Œ (åŒ…å« ç­‰çº§, åç§°, ç‰ˆæœ¬) ---
        name_tag = soup.select_one('h1')
        full_title = name_tag.get_text(strip=True) if name_tag else ""
        
        card_name = "N/A"
        card_rarity = "N/A"
        card_set = "N/A"
        
        if full_title:
            # 1. æå– ç­‰çº§ (Rarity)
            rarity_match = re.match(r'^([A-Z0-9\-]+)', full_title)
            if rarity_match:
                card_rarity = rarity_match.group(1).strip()
                remainder = full_title[len(rarity_match.group(0)):].strip()
            else:
                remainder = full_title
                card_rarity = "N/A"
            
            # 2. æå– åç§°
            name_match = re.match(r'([^(\s]+)', remainder)
            if name_match:
                card_name = name_match.group(1).strip()
            else:
                card_name = remainder.strip() 

            # 3. æå– ç‰ˆæœ¬ (Set)
            set_matches = re.findall(r'\(([^)]+)\)', full_title)
            if set_matches:
                card_set = " / ".join(set_matches).strip()
            else:
                card_set = "N/A"
        
        # --- 4. æå– å¡ç‰Œç¼–å· (OP07-064) ---
        card_number = "N/A"
        number_pattern = r'[A-Z0-9]{2,}\-\d{2,}'
        
        page_text = soup.get_text()
        number_matches = re.findall(number_pattern, page_text)
        
        if number_matches:
            card_number = number_matches[0] 

        # --- 5. æå– å›¾ç‰‡é“¾æ¥ ---
        match = re.search(r'yuyu-tei\.jp/sell/opc/card/([^/]+)/(\d+)', url)
        image_url = None
        if match:
            category_path = match.group(1) 
            card_id = match.group(2)       
            image_url = YUYU_TEI_BASE_IMAGE_URL + category_path + '/' + card_id + '.jpg'

        return {
            "card_name": card_name,
            "card_number": card_number,
            "card_set": card_set,
            "card_rarity": card_rarity,
            "image_url": image_url,
            "error": None
        }

    except requests.exceptions.RequestException as e:
        return {"error": f"ç½‘ç»œé”™è¯¯æˆ–æ— æ³•è®¿é—®: {e}"}
    except Exception as e:
        return {"error": f"è§£æç½‘é¡µæ—¶å‘ç”Ÿé”™è¯¯: {e}. è¯·æ£€æŸ¥HTMLç»“æ„æ˜¯å¦å˜åŒ–ã€‚"}

# --- Streamlit Session State ---
if 'scrape_result' not in st.session_state:
    st.session_state['scrape_result'] = {}
    
# --- æ¸…é™¤å‡½æ•° (ä½¿ç”¨ on_click æ¨¡å¼) ---
def clear_all_data():
    """åœ¨ç‚¹å‡»æ—¶æ‰§è¡Œçš„å›è°ƒå‡½æ•°ï¼Œç”¨äºæ¸…é™¤æ‰€æœ‰ session state æ•°æ®ï¼ŒåŒ…æ‹¬ URL è¾“å…¥æ¡†çš„å†…å®¹"""
    st.session_state['scrape_result'] = {} 
    st.session_state['scrape_url_input'] = ""
    
# === ç•Œé¢å¸ƒå±€ ===
st.set_page_config(page_title="å¡ç‰Œè¡Œæƒ…åˆ†æPro", page_icon="ğŸ“ˆ", layout="wide")

# --- ä¾§è¾¹æ ï¼šå½•å…¥ ---
with st.sidebar:
    st.header("ğŸŒ ç½‘é¡µè‡ªåŠ¨å¡«å…… (yuyu-tei)")
    
    scrape_url = st.text_input("è¾“å…¥å¡ç‰Œè¯¦æƒ…é¡µç½‘å€:", 
                               key='scrape_url_input') 
    
    col_scrape_btn, col_clear_btn = st.columns(2)
    
    with col_scrape_btn:
        if st.button("ä¸€é”®æŠ“å–å¹¶å¡«å……", type="secondary"):
            if not scrape_url:
                 st.warning("è¯·è¾“å…¥ç½‘å€åå†ç‚¹å‡»æŠ“å–ã€‚")
            else:
                st.session_state['scrape_result'] = scrape_card_data(scrape_url)
                if st.session_state['scrape_result']['error']:
                    st.error(st.session_state['scrape_result']['error'])
                else:
                    st.success("æ•°æ®æŠ“å–å®Œæˆï¼Œå·²è‡ªåŠ¨å¡«å……ä¸‹æ–¹è¡¨å•ã€‚")
                 
    with col_clear_btn:
        st.button("ä¸€é”®æ¸…é™¤å½•å…¥å†…å®¹", type="primary", on_click=clear_all_data)

    st.divider()
    st.header("ğŸ“ æ‰‹åŠ¨å½•å…¥/ä¿®æ­£")
    
    # é¢„å¡«å……æŠ“å–ç»“æœ
    name_default = st.session_state['scrape_result'].get('card_name', "")
    number_default = st.session_state['scrape_result'].get('card_number', "")
    set_default = st.session_state['scrape_result'].get('card_set', "")
    rarity_default = st.session_state['scrape_result'].get('card_rarity', "")
    img_url_default = st.session_state['scrape_result'].get('image_url', "")

    # å½•å…¥å­—æ®µé¡ºåº: 1.ç¼–å· -> 2.åç§° -> 3.ç‰ˆæœ¬ -> 4.ç­‰çº§ -> 5.ä»·æ ¼ -> 6.æ•°é‡ -> 7.æ—¥æœŸ
    card_number_in = st.text_input("1. å¡ç‰Œç¼–å·", value=number_default)
    name_in = st.text_input("2. å¡ç‰Œåç§° (å¿…å¡«)", value=name_default)
    set_in = st.text_input("3. ç³»åˆ—/ç‰ˆæœ¬", value=set_default) 
    rarity_in = st.text_input("4. ç­‰çº§ (Rarity)", value=rarity_default) 
    
    price_in = st.number_input("5. ä»·æ ¼ (Â¥)", min_value=0.0, step=10.0)
    quantity_in = st.number_input("6. æ•°é‡ (å¼ )", min_value=1, step=1)
    
    date_in = st.date_input("7. å½•å…¥æ—¥æœŸ", datetime.now())

    st.divider()
    st.write("ğŸ–¼ï¸ å¡ç‰Œå›¾ç‰‡ (å¯ä¿®æ­£)")
    # ç§»é™¤äº†æœ¬åœ°ä¸Šä¼ é€‰é¡¹
    img_source = st.radio("é€‰æ‹©å›¾ç‰‡æ¥æº:", ["æ— ", "ç½‘ç»œé“¾æ¥"], horizontal=True, 
                          index=1 if img_url_default else 0) 

    final_image_path = None
    
    if img_source == "ç½‘ç»œé“¾æ¥":
        image_url_input = st.text_input("è¾“å…¥å›¾ç‰‡ç½‘å€ (URL)", value=img_url_default)
        if image_url_input:
            try:
                st.image(image_url_input, caption="é¢„è§ˆ", use_container_width=True)
                final_image_path = image_url_input
            except: 
                st.error("æ— æ³•åŠ è½½è¯¥é“¾æ¥çš„å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥ç½‘å€æ˜¯å¦æ­£ç¡®ã€‚")
    
    # ç¡®å®šæœ€ç»ˆå›¾ç‰‡è·¯å¾„ï¼Œå¯¹äºäº‘ç«¯éƒ¨ç½²ï¼Œåªèƒ½æ˜¯ URL
    if img_source == "ç½‘ç»œé“¾æ¥":
        final_image_path = image_url_input
    else:
        final_image_path = None

    if st.button("æäº¤å½•å…¥", type="primary"):
        if name_in:
            # è°ƒç”¨æ–°çš„ add_card å‡½æ•° (å†™å…¥ Google Sheets)
            add_card(name_in, card_number_in, set_in, rarity_in, price_in, quantity_in, date_in, final_image_path)
            
            st.session_state['scrape_result'] = {}
            st.success(f"å·²å½•å…¥: {name_in} - Â¥{price_in} x {quantity_in} å¼ ")
            st.rerun()
        else:
            st.error("å¡ç‰Œåç§°ä¸èƒ½ä¸ºç©ºï¼")

# --- ä¸»é¡µé¢ ---
st.title("ğŸ“ˆ å¡ç‰Œå†å²ä¸ä»·æ ¼åˆ†æ Pro")

# è°ƒç”¨æ–°çš„ load_data å‡½æ•°
df = load_data()

if df.empty:
    st.info("ğŸ‘‹ æ¬¢è¿ï¼è¯·åœ¨å·¦ä¾§å½•å…¥ä½ çš„ç¬¬ä¸€å¼ å¡ç‰Œæ•°æ®ã€‚")
else:
    # é¢„å¤„ç†
    # ç¡®ä¿ id åˆ—æ˜¯æ•°å­—ç±»å‹
    df['id'] = pd.to_numeric(df['id'], errors='coerce').fillna(0).astype(int) 
    df['date_dt'] = pd.to_datetime(df['date'], errors='coerce')
    df['image_url'] = df['image_url'].fillna('')
    df['rarity'] = df['rarity'].fillna('')
    df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce').fillna(1).astype(int)
