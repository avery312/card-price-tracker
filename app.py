import streamlit as st
import pandas as pd
# æ˜ç¡®å¯¼å…¥ datetime å’Œ date å¯¹è±¡
from datetime import datetime, date 
import requests
from bs4 import BeautifulSoup
import re 
import numpy as np 
# å¯¼å…¥ Supabase å®¢æˆ·ç«¯åº“
from supabase import create_client, Client 
import time 

# === é…ç½® ===
SUPABASE_TABLE_NAME = "cards" 
NEW_EXPECTED_COLUMNS = ['id', 'date', 'card_number', 'card_name', 'card_set', 'price', 'quantity', 'rarity', 'color', 'image_url']

# --- Streamlit Session State ---
if 'scrape_result' not in st.session_state:
    st.session_state['scrape_result'] = {}
if 'form_key_suffix' not in st.session_state: 
    st.session_state['form_key_suffix'] = 0

if 'submission_successful' not in st.session_state: 
    st.session_state['submission_successful'] = False
if 'submitted_card_name' not in st.session_state: 
    st.session_state['submitted_card_name'] = "" 

if 'last_entry_date' not in st.session_state:
    st.session_state['last_entry_date'] = datetime.now().date() 
    
# æ–°å¢ Session state for autosave messages (ç”¨äºæ˜¾ç¤ºè‡ªåŠ¨ä¿å­˜ç»“æœ)
if 'autosave_successful' not in st.session_state:
    st.session_state['autosave_successful'] = False
if 'autosave_message' not in st.session_state:
    st.session_state['autosave_message'] = ""
    
# æ–°å¢ Session state for filter persistence (ç”¨äºä¿æŒç­›é€‰çŠ¶æ€)
if 'date_range_input' not in st.session_state:
    st.session_state['date_range_input'] = [] 
if 'search_name_input' not in st.session_state:
    st.session_state['search_name_input'] = ""
if 'search_set_input' not in st.session_state:
    st.session_state['search_set_input'] = ""


def clear_all_data():
    """æ¸…é™¤æ‰€æœ‰å½•å…¥ç›¸å…³ Session Stateã€‚"""
    st.session_state['scrape_result'] = {} 
    st.session_state['form_key_suffix'] += 1 
    st.session_state['last_entry_date'] = datetime.now().date() 

def clear_search_filters_action():
    """æ¸…é™¤æ‰€æœ‰ç­›é€‰ç›¸å…³çš„ Session State å˜é‡ã€‚ç”¨äº on_click å›è°ƒã€‚"""
    st.session_state["search_name_input"] = ""
    st.session_state["search_set_input"] = ""
    st.session_state["date_range_input"] = [] 


# === è¾…åŠ©å‡½æ•°ï¼šæ¨¡ç³Šæœç´¢è§„èŒƒåŒ– ===
def normalize_text_for_fuzzy_search(text):
    if pd.isna(text):
        return ""
    cleaned = str(text).replace('-', '').replace(' ', '')
    return cleaned.upper()

# === Supabase æ•°æ®åº“å‡½æ•° ===

@st.cache_resource(ttl=None)
def connect_supabase() -> Client:
    """ä½¿ç”¨ Streamlit Secrets å‡­è¯è¿æ¥åˆ° Supabase æ•°æ®åº“ (è¿æ¥å¯¹è±¡ç¼“å­˜)"""
    try:
        url: str = st.secrets["supabase"]["URL"]
        key: str = st.secrets["supabase"]["KEY"]
        supabase: Client = create_client(url, key)
        return supabase
    except Exception as e:
        st.error(f"æ— æ³•è¿æ¥ Supabase æ•°æ®åº“ã€‚è¯·æ£€æŸ¥ secrets.toml é…ç½®ã€‚é”™è¯¯: {e}")
        return None

def load_data():
    """ä» Supabase è¯»å–æ‰€æœ‰æ•°æ® (æ¯æ¬¡è„šæœ¬è¿è¡Œæ—¶éƒ½å¼ºåˆ¶è¯»å–)"""
    supabase = connect_supabase()
    if not supabase:
        return pd.DataFrame(columns=NEW_EXPECTED_COLUMNS)
    
    try:
        # ç›´æ¥è¯»å–æ•°æ®
        response = supabase.table(SUPABASE_TABLE_NAME).select("*").order("date", desc=True).execute()
        
        df = pd.DataFrame(response.data)
        
        if df.empty:
             return pd.DataFrame(columns=NEW_EXPECTED_COLUMNS)

        df = df.replace({np.nan: None}) 
        df['id'] = pd.to_numeric(df['id'], errors='coerce').fillna(0).astype(int)
        
        df = df[NEW_EXPECTED_COLUMNS] 

        return df
    except Exception as e:
        st.error(f"æ— æ³•ä» Supabase è¯»å–æ•°æ®ã€‚é”™è¯¯: {e}")
        return pd.DataFrame(columns=NEW_EXPECTED_COLUMNS)

# æ–°å¢/è¿½åŠ å¡ç‰Œ
def add_card(name, number, card_set, price, quantity, rarity, color, date, image_url=None):
    supabase = connect_supabase()
    if not supabase: return
    
    try:
        # 1. ç›´æ¥æŸ¥è¯¢ Supabase è·å–æœ€å¤§çš„ ID 
        response = supabase.table(SUPABASE_TABLE_NAME).select("id").order("id", desc=True).limit(1).execute()
        
        max_id = 0
        if response.data and response.data[0] and 'id' in response.data[0]:
            # æ‰¾åˆ°å½“å‰æœ€å¤§çš„ ID
            max_id = response.data[0]['id']
            
        new_id = int(max_id + 1) if pd.notna(max_id) else 1
        
        # 2. å‡†å¤‡è¦æ’å…¥çš„å­—å…¸æ•°æ®
        new_row_data = {
            "id": new_id,
            "date": date.strftime('%Y-%m-%d'),
            "card_number": number,
            "card_name": name,
            "card_set": card_set,
            "price": price,
            "quantity": quantity,
            "rarity": rarity,
            "color": color,
            "image_url": image_url if image_url else ""
        }
        
        # 3. æ‰§è¡Œæ’å…¥æ“ä½œ
        supabase.table(SUPABASE_TABLE_NAME).insert(new_row_data).execute()
        
    except Exception as e:
        st.error(f"è¿½åŠ æ•°æ®åˆ° Supabase å¤±è´¥ã€‚é”™è¯¯: {e}")

# ã€æ ¸å¿ƒåŠŸèƒ½ï¼šå®ç°å¢é‡è‡ªåŠ¨ä¿å­˜ï¼Œå·²ä¿®å¤æ—¥æœŸéç©ºçº¦æŸé—®é¢˜ã€‘
def save_incremental_changes(displayed_df: pd.DataFrame, editor_state: dict):
    """
    æ ¹æ® data_editor çš„çŠ¶æ€ï¼Œå¯¹ Supabase è¿›è¡Œç²¾ç¡®çš„ UPSERT å’Œ DELETE æ“ä½œã€‚
    - displayed_df æ˜¯ data_editor å½“å‰æ˜¾ç¤ºçš„ (å·²ç­›é€‰ä¸”**å·²é‡ç½®ç´¢å¼•**) çš„ DataFrameã€‚
    - editor_state åŒ…å«è¢«ç¼–è¾‘å’Œè¢«åˆ é™¤çš„è¡Œç´¢å¼• (åŸºäº 0-based è¿ç»­ç´¢å¼•)ã€‚
    """
    supabase = connect_supabase()
    if not supabase: return
    
    deleted_count = 0
    updated_count = 0
    
    try:
        # 1. å¤„ç†åˆ é™¤æ“ä½œ (DELETE)
        deleted_indices = editor_state.get("deleted_rows", [])
        if deleted_indices:
            # æ ¹æ® 0-based ç´¢å¼•ä»æ˜¾ç¤ºçš„ DataFrame ä¸­è·å–è¦åˆ é™¤çš„è®°å½•çš„ ID
            # è¿™ä¸€æ­¥æ˜¯å®ç°æ•´è¡Œåˆ é™¤çš„å…³é”®ï¼šé€šè¿‡ Streamlit è¿”å›çš„ç´¢å¼•æ‰¾åˆ°å¯¹åº”çš„ ID
            ids_to_delete = displayed_df.iloc[deleted_indices]['id'].tolist()
            
            if ids_to_delete:
                deleted_count = len(ids_to_delete)
                # ä½¿ç”¨ Supabase çš„ `in` è¿‡æ»¤å™¨è¿›è¡Œæ‰¹é‡åˆ é™¤
                supabase.table(SUPABASE_TABLE_NAME).delete().in_('id', ids_to_delete).execute()

        # 2. å¤„ç†ä¿®æ”¹æ“ä½œ (UPSERT/UPDATE)
        edited_rows = editor_state.get("edited_rows", {})
        if edited_rows:
            data_to_upsert = []
            
            for filtered_index, changes in edited_rows.items():
                # æ£€æŸ¥è¿™ä¸ªç´¢å¼•æ˜¯å¦åŒæ—¶è¢«åˆ é™¤ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™è·³è¿‡ï¼ˆåˆ é™¤ä¼˜å…ˆï¼‰
                if filtered_index in deleted_indices:
                    continue
                    
                # è·å–åŸå§‹ IDï¼Œå®ƒæ˜¯æ›´æ–°è®°å½•çš„å”¯ä¸€æ ‡è¯†
                row_id = displayed_df.iloc[filtered_index]['id']
                
                # åˆ›å»ºä¸€ä¸ªåªåŒ…å« ID å’Œæ‰€æœ‰ä¿®æ”¹åˆ—çš„æ•°æ®å­—å…¸
                update_data = {'id': int(row_id)}
                
                # è·å–åŸå§‹æ—¥æœŸå¯¹è±¡
                original_date_obj = displayed_df.iloc[filtered_index]['date']
                
                # --- ã€æ—¥æœŸéç©ºä¿®æ­£æ ¸å¿ƒé€»è¾‘ã€‘ ---
                # ç›®æ ‡ï¼šç¡®ä¿ update_data åœ¨å‘é€ç»™ Supabase æ—¶å§‹ç»ˆåŒ…å« 'date' é”®ï¼Œä¸”å€¼ä¸ºéç©ºå­—ç¬¦ä¸²ã€‚
                initial_date_str = datetime.now().strftime('%Y-%m-%d') # ç»ˆæå›é€€å€¼
                
                # å¦‚æœ original_date_obj æ˜¯æœ‰æ•ˆçš„æ—¥æœŸå­—ç¬¦ä¸²æˆ–å¯¹è±¡ï¼Œå°è¯•æå–å…¶ YYYY-MM-DD æ ¼å¼
                if original_date_obj:
                    if isinstance(original_date_obj, date):
                        initial_date_str = original_date_obj.strftime('%Y-%m-%d')
                    elif isinstance(original_date_obj, str):
                         # å‡è®¾åŸå§‹å­—ç¬¦ä¸²æ˜¯æœ‰æ•ˆçš„ YYYY-MM-DD
                        try:
                           datetime.strptime(original_date_obj, '%Y-%m-%d')
                           initial_date_str = original_date_obj
                        except:
                           # å¦‚æœä¸æ˜¯æœ‰æ•ˆæ ¼å¼ï¼Œåˆ™ä¿ç•™å›é€€å€¼
                           pass
                
                # æ— è®ºå¦‚ä½•ï¼Œå…ˆè®¾ç½®ä¸€ä¸ªæœ‰æ•ˆçš„æ—¥æœŸå€¼ (åŸå§‹å€¼æˆ–ä»Šå¤©çš„å€¼)
                update_data['date'] = initial_date_str 
                # --- ä¿®æ­£ç»“æŸ ---
                
                # éå†æ‰€æœ‰ä¿®æ”¹çš„åˆ—åŠå…¶å€¼
                for col, value in changes.items():
                    
                    # æ•°æ®ç±»å‹è½¬æ¢å’Œæ¸…ç†
                    if col == 'date':
                        # å¦‚æœ date è¢«ä¿®æ”¹ï¼Œåˆ™å°è¯•ä½¿ç”¨ç¼–è¾‘åçš„å€¼è¿›è¡Œè½¬æ¢å’Œè¦†ç›–
                        final_date_str_edit = None
                        
                        if value:
                            # 1. å¦‚æœæ˜¯ Streamlit DateColumn è¿”å›çš„ date/datetime å¯¹è±¡
                            if isinstance(value, (datetime, pd.Timestamp, date)): 
                                try:
                                    final_date_str_edit = value.strftime('%Y-%m-%d')
                                except:
                                    pass 
                            # 2. å¦‚æœæ˜¯å­—ç¬¦ä¸² (ä¾‹å¦‚ç”¨æˆ·åœ¨å•å…ƒæ ¼ä¸­æ‰‹åŠ¨è¾“å…¥)
                            elif isinstance(value, str):
                                # æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æ—¥æœŸæ ¼å¼
                                try:
                                    datetime.strptime(value, '%Y-%m-%d')
                                    final_date_str_edit = value
                                except:
                                    pass
                        
                        # åªæœ‰ç¼–è¾‘åçš„å€¼æœ‰æ•ˆæ—¶æ‰è¦†ç›– update_data['date']
                        if final_date_str_edit is not None:
                            update_data[col] = final_date_str_edit 
                        # å¦‚æœç¼–è¾‘å€¼æ— æ•ˆï¼Œå°†ä¿ç•™ä¿®æ­£æ­¥éª¤ä¸­è®¾ç½®çš„ initial_date_str

                    elif col in ['price']:
                        update_data[col] = float(value) if pd.notna(value) else 0.0
                    elif col in ['quantity']:
                        update_data[col] = int(value) if pd.notna(value) else 0
                    else:
                        update_data[col] = str(value) if pd.notna(value) else ""
                        
                # å°†åŒ…å« ID å’Œä¿®æ”¹å€¼çš„å­—å…¸æ·»åŠ åˆ°å¾…æ›´æ–°åˆ—è¡¨
                data_to_upsert.append(update_data)
            
            if data_to_upsert:
                updated_count = len(data_to_upsert)
                # Supabase UPSERT (æ ¹æ®ä¸»é”® 'id' è‡ªåŠ¨æ›´æ–°æˆ–æ’å…¥)
                supabase.table(SUPABASE_TABLE_NAME).upsert(data_to_upsert).execute()

        
        if deleted_count > 0 or updated_count > 0:
            msg = f"âœ… å·²è‡ªåŠ¨ä¿å­˜ï¼šæ›´æ–° {updated_count} æ¡ï¼Œåˆ é™¤ {deleted_count} æ¡ã€‚"
            st.session_state['autosave_successful'] = True
            st.session_state['autosave_message'] = msg
        
    except Exception as e:
        # æ•è·ä»»ä½•å¯èƒ½çš„é”™è¯¯ï¼Œå¹¶è®¾ç½®é”™è¯¯æ¶ˆæ¯ï¼Œè®©ä¸»ç¨‹åºæ˜¾ç¤º
        st.session_state['autosave_successful'] = True
        st.session_state['autosave_message'] = f"âŒ è‡ªåŠ¨ä¿å­˜å¤±è´¥ã€‚é”™è¯¯: {e}"


# ç½‘é¡µæŠ“å–å‡½æ•° (ä¿æŒä¸å˜)
def scrape_card_data(url):
    st.info(f"æ­£åœ¨å°è¯•ä» {url} æŠ“å–æ•°æ®...")
    if not url.startswith("http"):
        return {"error": "ç½‘å€æ ¼å¼ä¸æ­£ç¡®ã€‚"}
    
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, timeout=10, headers=headers)
        response.raise_for_status() 
        response.encoding = response.apparent_encoding
        soup = BeautifulSoup(response.content, 'html.parser')

        name_tag = soup.find(['h1', 'h2'], class_=re.compile(r'heading|title', re.I))
        full_title = name_tag.get_text(strip=True) if name_tag else ""
        
        if not full_title:
             return {"error": "æœªèƒ½æ‰¾åˆ°å¡ç‰Œåç§°æ ‡é¢˜ã€‚"}

        card_name = "N/A"; rarity = "N/A"; color = "N/A"; card_number = "N/A"; card_set = "" 
        temp_title = full_title 

        # 1. æå– rarity
        rarity_match = re.search(r'ã€(.+?)ã€‘', temp_title)
        if rarity_match:
            rarity = rarity_match.group(1).strip()
            temp_title = temp_title.replace(rarity_match.group(0), ' ').strip()
        
        # 2. æå– color
        color_match = re.search(r'ã€Š(.+?)ã€‹', temp_title)
        if color_match:
            color = color_match.group(1).strip()
            temp_title = temp_title.replace(color_match.group(0), ' ').strip()
        
        # 3. æå– card_number
        number_match = re.search(r'([A-Z0-9]{1,}\-\d{2,})', temp_title) 
        
        if number_match:
            card_number = number_match.group(1).strip()
            temp_title_without_number = temp_title[:number_match.start()] + temp_title[number_match.end():]
        else:
            temp_title_without_number = temp_title
        
        # 4. æå– card_set å’Œ card_name
        name_part = re.match(r'(.+?)[\s\[ã€]', temp_title_without_number.strip())
        if name_part:
            card_name = name_part.group(1).strip()
            card_set = temp_title_without_number[len(name_part.group(0)):].strip()
        else:
            card_name = temp_title_without_number.strip()
            card_set = ""
            
        card_set = re.sub(r'[\[\]ã€ã€]', '', card_set).strip()
        
        # --- 5. æå–å›¾ç‰‡é“¾æ¥ ---
        image_url = None
        
        og_image_tag = soup.find('meta', property='og:image')
        if og_image_tag:
            image_url = og_image_tag.get('content')
            
        if not image_url:
            image_tag = soup.find('img', {'alt': lambda x: x and 'ãƒ¡ã‚¤ãƒ³ç”»åƒ' in x}) or \
                        soup.find('img', {'alt': lambda x: x and card_name in x})
            
            if image_tag:
                image_url = image_tag.get('data-src') or image_tag.get('src') 
        
        if not image_url:
            st.warning("æœªèƒ½æ‰¾åˆ°å›¾ç‰‡é“¾æ¥ã€‚")

        return {
            "card_name": card_name, "card_number": card_number, "card_set": card_set,
            "card_rarity": rarity, "card_color": color, "image_url": image_url, "error": None
        }

    except requests.exceptions.RequestException as e:
        return {"error": f"ç½‘ç»œé”™è¯¯æˆ–æ— æ³•è®¿é—®: {e}"}
    except Exception as e:
        return {"error": f"è§£æé”™è¯¯: {e}"}

# === ç•Œé¢å¸ƒå±€ ===
st.set_page_config(page_title="å¡ç‰Œè¡Œæƒ…åˆ†æPro", page_icon="ğŸ“ˆ", layout="wide")

suffix = str(st.session_state['form_key_suffix']) 

# --- ä¾§è¾¹æ ï¼šå½•å…¥ ---
with st.sidebar:
    if st.session_state.get('submission_successful'):
        card_name = st.session_state.get('submitted_card_name', 'ä¸€å¼ å¡ç‰Œ')
        st.success(f"âœ… **{card_name}** å½•å…¥æˆåŠŸï¼", icon="ğŸ‰") 
        
    st.header("ğŸŒ ç½‘é¡µè‡ªåŠ¨å¡«å……")
    scrape_url = st.text_input("è¾“å…¥å¡ç‰Œè¯¦æƒ…é¡µç½‘å€:", key=f'scrape_url_input_{suffix}') 
    
    col_scrape_btn, col_clear_btn = st.columns(2)
    
    with col_scrape_btn:
        if st.button("ä¸€é”®æŠ“å–å¹¶å¡«å……", type="secondary", key=f"scrape_btn_{suffix}"):
            if not scrape_url: st.warning("è¯·è¾“å…¥ç½‘å€ã€‚")
            else:
                st.session_state['scrape_result'] = scrape_card_data(scrape_url)
                if st.session_state['scrape_result']['error']: st.error(st.session_state['scrape_result']['error'])
                else: st.success("æ•°æ®æŠ“å–å®Œæˆã€‚")
                st.session_state['form_key_suffix'] += 1
                st.rerun() 
                 
    with col_clear_btn:
        if st.button("ä¸€é”®æ¸…é™¤å½•å…¥å†…å®¹", type="primary", key=f"clear_btn_{suffix}"):
            clear_all_data()
            st.rerun() 

    st.divider()
    st.header("ğŸ“ æ‰‹åŠ¨å½•å…¥/ä¿®æ­£")
    
    res = st.session_state['scrape_result']
    name_default = res.get('card_name', "")
    number_default = res.get('card_number', "")
    set_default = res.get('card_set', "")
    rarity_default = res.get('card_rarity', "") 
    color_default = res.get('card_color', "") 
    img_url_default = res.get('image_url', "")

    
    with st.form(key=f"manual_entry_form_{suffix}"):
        card_number_in = st.text_input("1. å¡ç‰Œç¼–å·", value=number_default, key=f"card_number_in_form_{suffix}")
        name_in = st.text_input("2. å¡ç‰Œåç§° (å¿…å¡«)", value=name_default, key=f"name_in_form_{suffix}")
        set_in = st.text_input("3. ç³»åˆ—/ç‰ˆæœ¬", value=set_default, key=f"set_in_form_{suffix}") 
        rarity_in = st.text_input("4. ç­‰çº§ (Rarity)", value=rarity_default, key=f"rarity_in_form_{suffix}") 
        color_in = st.text_input("5. é¢œè‰² (ä¾‹å¦‚: ç´«)", value=color_default, key=f"color_in_form_{suffix}") 
        
        price_in = st.number_input("6. ä»·æ ¼ (Â¥)", min_value=0.0, step=10.0, key=f"price_in_form_{suffix}")
        quantity_in = st.number_input("7. æ•°é‡ (å¼ )", min_value=1, step=1, key=f"quantity_in_form_{suffix}")
        
        date_in = st.date_input(
            "8. å½•å…¥æ—¥æœŸ", 
            value=st.session_state['last_entry_date'],
            key=f"date_in_form_{suffix}"
        )

        st.divider()
        st.write("ğŸ–¼ï¸ å¡ç‰Œå›¾ç‰‡ (å¯ä¿®æ­£)")

        image_url_input = st.text_input("è¾“å…¥å›¾ç‰‡ç½‘å€ (URL)", value=img_url_default, key=f"image_url_input_form_{suffix}")
        final_image_path = image_url_input if image_url_input else None
        
        if final_image_path:
            try:
                st.image(final_image_path, caption="é¢„è§ˆ", use_container_width=True)
            except: 
                st.warning("æ— æ³•åŠ è½½è¯¥é“¾æ¥çš„å›¾ç‰‡ã€‚")

        submitted = st.form_submit_button("æäº¤å½•å…¥", type="primary")

    if submitted:
        if name_in:
            with st.spinner("ğŸš€ æ•°æ®å³æ—¶ä¿å­˜ä¸­..."):
                add_card(name_in, card_number_in, set_in, price_in, quantity_in, rarity_in, color_in, date_in, final_image_path)
            
            st.session_state['last_entry_date'] = date_in

            st.session_state['scrape_result'] = {}
            st.session_state['form_key_suffix'] += 1
            
            st.session_state['submission_successful'] = True
            st.session_state['submitted_card_name'] = name_in
            
            st.rerun() 
        else:
            st.error("å¡ç‰Œåç§°ä¸èƒ½ä¸ºç©ºï¼")

# --- ä¸»é¡µé¢ ---
st.title("ğŸ“ˆ å¡ç‰Œå†å²ä¸ä»·æ ¼åˆ†æ Pro")

# æ£€æŸ¥å¹¶æ˜¾ç¤ºè‡ªåŠ¨ä¿å­˜ç»“æœ
if st.session_state.get('autosave_successful'):
    if "âŒ" in st.session_state['autosave_message']:
        st.error(st.session_state['autosave_message'])
    else:
        st.success(st.session_state['autosave_message'])
        
    st.session_state['autosave_successful'] = False
    st.session_state['autosave_message'] = ""
    
# æ£€æŸ¥å¹¶æ˜¾ç¤ºå½•å…¥ç»“æœ
if st.session_state.get('submission_successful'):
    card_name = st.session_state.get('submitted_card_name', 'ä¸€å¼ å¡ç‰Œ')
    st.success(f"âœ… å·²æˆåŠŸå½•å…¥: **{card_name}**ã€‚é¡µé¢å·²è‡ªåŠ¨è¿”å›é¡¶éƒ¨ã€‚")
    st.session_state['submission_successful'] = False
    st.session_state['submitted_card_name'] = ""

df = load_data() 

if df.empty:
    st.info("ğŸ‘‹ æ¬¢è¿ï¼è¯·åœ¨å·¦ä¾§å½•å…¥ä½ çš„ç¬¬ä¸€å¼ å¡ç‰Œæ•°æ®ã€‚")
else:
    # é¢„å¤„ç†
    df['date_dt'] = pd.to_datetime(df['date'], errors='coerce')
    df['image_url'] = df['image_url'].fillna('')
    df['rarity'] = df['rarity'].fillna('') 
    df['color'] = df['color'].fillna('') 
    df['card_set'] = df['card_set'].fillna('') 
    df['card_number'] = df['card_number'].fillna('') 
    df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce').fillna(1).astype(int) 
    df = df.dropna(subset=['date_dt']) 
    
    # --- ğŸ” å¤šç»´åº¦ç­›é€‰ ---
    st.markdown("### ğŸ” å¤šç»´åº¦ç­›é€‰")
    
    col_s1, col_s2, col_s3, col_s4 = st.columns([3, 3, 3, 1]) 
    
    with col_s1: 
        # ä½¿ç”¨ Session State å˜é‡ä¿æŒè¾“å…¥æ¡†çš„å€¼
        search_name = st.text_input("æœç´¢ åç§°/ç¼–å·/ID", value=st.session_state["search_name_input"], help="æ”¯æŒæ¨¡ç³Šæœç´¢", key="search_name_input") 
    with col_s2: 
        search_set = st.text_input("æœç´¢ ç³»åˆ—/ç‰ˆæœ¬", value=st.session_state["search_set_input"], key="search_set_input")
    with col_s3: 
        date_range = st.date_input(
            "æœç´¢ æ—¶é—´èŒƒå›´", 
            value=st.session_state.get("date_range_input", []), 
            help="è¯·é€‰æ‹©å¼€å§‹å’Œç»“æŸæ—¥æœŸ", 
            key="date_range_input"
        )
    
    with col_s4: 
        st.write(" ") 
        # ä½¿ç”¨å›è°ƒå‡½æ•°æ¸…ç©ºç­›é€‰çŠ¶æ€
        st.button(
            "æ¸…ç©ºç­›é€‰", 
            key="clear_filters_btn", 
            use_container_width=True,
            on_click=clear_search_filters_action
        ) 

    # --- ç­›é€‰é€»è¾‘ (ç”¨äºç¼–è¾‘å’Œåˆ†æ) ---
    filtered_df = df.copy()
    
    if search_name:
        cleaned_search_name = normalize_text_for_fuzzy_search(search_name)
        search_target = (
            filtered_df['card_name'].astype(str).apply(normalize_text_for_fuzzy_search) + 
            filtered_df['card_number'].astype(str).apply(normalize_text_for_fuzzy_search) + 
            filtered_df['id'].astype(str).apply(normalize_text_for_fuzzy_search)
        )
        search_condition = search_target.str.contains(cleaned_search_name, case=False, na=False)
        filtered_df = filtered_df[search_condition]
        
    if search_set:
        filtered_df = filtered_df[filtered_df['card_set'].str.contains(search_set, case=False, na=False)]
    if len(date_range) == 2:
        # ç¡®ä¿ date_range åŒ…å«ä¸¤ä¸ªæ—¥æœŸ
        filtered_df = filtered_df[(filtered_df['date_dt'].dt.date >= date_range[0]) & (filtered_df['date_dt'].dt.date <= date_range[1])]

    
    # --- ğŸ“ æ•°æ®ç¼–è¾‘åŒºåŸŸ ---
    
    st.markdown("### ğŸ“ æ•°æ®ç¼–è¾‘ï¼ˆè‡ªåŠ¨å¢é‡ä¿å­˜æ¨¡å¼ï¼‰")
    st.caption("âœ¨ **è‡ªåŠ¨å¢é‡ä¿å­˜**ï¼šåœ¨å•å…ƒæ ¼ä¸­å®Œæˆä¿®æ”¹åï¼Œç‚¹å‡»è¡¨æ ¼å¤–çš„ä»»ä½•ä½ç½®ï¼Œç³»ç»Ÿå°†**è‡ªåŠ¨ä¿å­˜**æ‚¨ä¿®æ”¹çš„å†…å®¹ã€‚")
    st.caption("ğŸš¨ **å®‰å…¨æç¤º**ï¼šæ­¤ç¼–è¾‘å™¨ä»…æ˜¾ç¤ºç­›é€‰ç»“æœã€‚æ‰€æœ‰ä¿®æ”¹å’Œåˆ é™¤å°†ä»…åº”ç”¨äºå±å¹•ä¸Šå¯è§çš„è®°å½•ã€‚")
    st.caption("âœ… **æ•´è¡Œåˆ é™¤**ï¼šè¡¨æ ¼**æœ€å·¦ä¾§**æ˜¯**è¡Œé€‰æ‹©å¤é€‰æ¡†**ã€‚å‹¾é€‰ä¸€è¡Œæˆ–å¤šè¡Œï¼Œç„¶åæŒ‰é”®ç›˜ä¸Šçš„ **`Delete`** é”®å³å¯æ‰§è¡Œåˆ é™¤æ“ä½œã€‚")
    
    # å‡†å¤‡ç”¨äºå±•ç¤ºå’Œç¼–è¾‘çš„ DataFrame (ä½¿ç”¨ç­›é€‰ç»“æœ)
    display_df = filtered_df.drop(columns=['date_dt'], errors='ignore')

    # ã€å…³é”®ä¿®æ­£åŒºåŸŸã€‘ï¼šç¡®ä¿æ—¥æœŸæ ¼å¼å…¼å®¹ st.data_editor
    # 1. ç¡®ä¿ 'date' å­—æ®µçš„ç©ºå€¼æ˜¯ None (è€Œä¸æ˜¯ NaT æˆ– NaN)
    #    - è¿™è®© st.data_editor æ›´å¥½åœ°å¤„ç†ç©º/æ— æ•ˆçš„æ—¥æœŸè¾“å…¥
    #    - å°†æœ‰æ•ˆæ—¥æœŸè½¬æ¢ä¸º 'YYYY-MM-DD' å­—ç¬¦ä¸²ï¼Œä»¥å¢å¼ºä¸ st.data_editor çš„å…¼å®¹æ€§
    date_series = pd.to_datetime(display_df['date'], errors='coerce')
    display_df['date'] = date_series.apply(lambda x: x.strftime('%Y-%m-%d') if pd.notna(x) else None)
    
    display_df = display_df.sort_values(by='id', ascending=False)
    
    # 2. å¼ºåˆ¶é‡ç½®ç´¢å¼•ï¼šç¡®ä¿ç´¢å¼•è¿ç»­
    display_df = display_df.reset_index(drop=True) 
    
    FINAL_DISPLAY_COLUMNS = ['date', 'card_number', 'card_name', 'card_set', 'price', 'quantity', 'rarity', 'color', 'image_url']
    
    # ç¡®ä¿ ID åˆ—åœ¨æœ€å‰é¢
    display_df = display_df[['id'] + FINAL_DISPLAY_COLUMNS]

    if display_df.empty:
        st.info("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆç­›é€‰æ¡ä»¶çš„æ•°æ®å¯ä¾›ç¼–è¾‘ã€‚")
        # ç¡®ä¿ session state ä¸­å­˜åœ¨ data_editor é”®ï¼Œé˜²æ­¢åç»­é€»è¾‘æŠ¥é”™
        if "data_editor" not in st.session_state:
            st.session_state["data_editor"] = {"edited_rows": {}, "deleted_rows": []}
    else:
        column_config_dict = {
            "id": st.column_config.Column("ID", disabled=True, width=50), 
            "date": st.column_config.DateColumn("å½•å…¥æ—¶é—´", width=80), 
            "card_number": st.column_config.Column("ç¼–å·", width=70),
            "card_name": st.column_config.Column("å¡å", width=200), 
            "card_set": st.column_config.Column("ç³»åˆ—", width=100), 
            "price": st.column_config.NumberColumn("ä»·æ ¼ (Â¥)", format="Â¥%d", width=70),
            "quantity": st.column_config.NumberColumn("æ•°é‡ (å¼ )", format="%d", width=50),
            "rarity": st.column_config.Column("ç­‰çº§", width=50), 
            "color": st.column_config.Column("é¢œè‰²", width=50), 
            "image_url": st.column_config.ImageColumn("å¡å›¾", width=50),
        }
        
        st.data_editor(
            display_df, 
            key="data_editor", # æ ¸å¿ƒï¼šå°†ç¼–è¾‘çŠ¶æ€å­˜å…¥ session state
            hide_index=True,
            column_order=['id'] + FINAL_DISPLAY_COLUMNS,
            column_config=column_config_dict,
            num_rows="fixed", # ä»…å…è®¸ä¿®æ”¹ç°æœ‰è¡Œå’Œåˆ é™¤è¡Œ (å…è®¸åˆ é™¤ç°æœ‰è¡Œ)
            # ç¡®ä¿äº†å¤šè¡Œé€‰æ‹©æ¨¡å¼ï¼Œç”¨äºæ˜¾ç¤ºåˆ é™¤å¤é€‰æ¡†
            selection_mode="multi-row",
            # ç§»é™¤ use_container_width=True ä»¥ç¡®ä¿å¤é€‰æ¡†å¯è§
        )

    # ã€æ ¸å¿ƒè‡ªåŠ¨ä¿å­˜/åˆ é™¤é€»è¾‘ã€‘
    editor_state = st.session_state.get("data_editor")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¼–è¾‘å˜åŠ¨æˆ–åˆ é™¤æ“ä½œ
    # å½“ç”¨æˆ·åœ¨å•å…ƒæ ¼å®Œæˆç¼–è¾‘æˆ–åˆ é™¤è¡Œåï¼Œst.data_editor ä¼šè‡ªåŠ¨æ›´æ–° session state å¹¶è§¦å‘ rerun
    if editor_state and (editor_state.get("edited_rows") or editor_state.get("deleted_rows")):
        
        # ç«‹å³è¿›è¡Œä¿å­˜ï¼Œå–ä»£æ‰‹åŠ¨ç¡®è®¤æŒ‰é’®
        st.info("ğŸ”„ æ£€æµ‹åˆ°ä¿®æ”¹æˆ–åˆ é™¤ï¼Œæ­£åœ¨è‡ªåŠ¨å¢é‡ä¿å­˜...")
        
        with st.spinner("ğŸš€ æ•°æ®å¢é‡è‡ªåŠ¨ä¿å­˜ä¸­..."):
            # è°ƒç”¨å¢é‡ä¿å­˜å‡½æ•°
            save_incremental_changes(display_df, editor_state)
        
        # å¿…é¡»è°ƒç”¨ rerun æ¥åˆ·æ–°æ•°æ®ï¼Œæ¸…é™¤ data_editor çš„çŠ¶æ€ï¼Œå¹¶æ˜¾ç¤ºä¿å­˜æˆåŠŸçš„æ¶ˆæ¯
        st.rerun()

    
    st.divider()
    
    # --- ğŸ“Š å•å¡æ·±åº¦åˆ†æé¢æ¿ (ä½¿ç”¨ç­›é€‰ç»“æœ) ---
    st.markdown("### ğŸ“Š å•å¡æ·±åº¦åˆ†æ")
    
    analysis_df = filtered_df.copy() 

    if analysis_df.empty:
        st.warning("æ— ç­›é€‰ç»“æœã€‚")
    else:
        analysis_df['unique_label'] = analysis_df.apply(
            lambda x: f"{x['card_name']} [{x['card_number']}] ({x['card_set']}) - {x['rarity']}/{x['color']}", 
            axis=1
        )
        
        unique_variants = analysis_df['unique_label'].unique()
        selected_variant = st.selectbox("è¯·é€‰æ‹©è¦åˆ†æçš„å…·ä½“å¡ç‰Œ:", unique_variants)
        
        target_df = analysis_df[analysis_df['unique_label'] == selected_variant].sort_values("date_dt")
        
        col_img, col_stat, col_chart = st.columns([1, 1, 2])
        
        with col_img:
            st.caption("å¡ç‰Œå¿«ç…§ (æœ€è¿‘ä¸€ç¬”)")
            latest_img = target_df.iloc[-1]['image_url']
            if latest_img:
                try:
                    st.image(latest_img, use_container_width=True) 
                except:
                    st.error("å›¾ç‰‡åŠ è½½å¤±è´¥")
            else:
                st.empty()
                st.caption("æš‚æ— å›¾ç‰‡")

        with col_stat:
            st.caption("ä»·æ ¼ç»Ÿè®¡")
            if not target_df.empty:
                curr_price = target_df.iloc[-1]['price']
                total_quantity = target_df['quantity'].sum()
                avg_price = target_df['price'].mean()
                
                max_price = target_df['price'].max()
                # ç¡®ä¿åœ¨å–æ—¥æœŸæ—¶ï¼Œdfä¸æ˜¯ç©ºçš„ï¼Œä¸”æ—¥æœŸæ˜¯æœ‰æ•ˆçš„
                max_price_date = target_df[target_df['price'] == max_price]['date'].iloc[0] if not target_df[target_df['price'] == max_price].empty else "N/A"
                
                min_price = target_df['price'].min()
                min_price_date = target_df[target_df['price'] == min_price]['date'].iloc[0] if not target_df[target_df['price'] == min_price].empty else "N/A"

                c1, c2 = st.columns(2)
                c1.metric("ğŸ’° æœ€æ–°æˆäº¤", f"Â¥{curr_price:,.0f}")
                c2.metric("ğŸ“¦ æ€»åº“å­˜", f"{total_quantity:,} å¼ ")
                
                st.divider()
                
                c3, c4 = st.columns(2)
                c3.metric("ğŸ“ˆ å†å²æœ€é«˜", f"Â¥{max_price:,.0f}", f"äº {max_price_date} å½•å…¥")
                c4.metric("ğŸ“‰ å†å²æœ€ä½", f"Â¥{min_price:,.0f}", f"äº {min_price_date} å½•å…¥")
                
                st.metric("ğŸ“Š å¹³å‡ä»·æ ¼", f"Â¥{avg_price:,.2f}")
                
                st.caption(f"å…± {len(target_df)} æ¡è®°å½•")
            else:
                st.info("æ— æ•°æ®ç»Ÿè®¡ã€‚")


        with col_chart:
            st.caption("ä»·æ ¼èµ°åŠ¿å›¾")
            if len(target_df) > 1:
                st.line_chart(target_df, x="date_dt", y="price", color="#FF4B4B")
            else:
                st.info("éœ€è‡³å°‘ä¸¤æ¡è®°å½•ç»˜åˆ¶èµ°åŠ¿")
        
        # æœ€è¿‘10æ¬¡å½•å…¥è®°å½•è¡¨æ ¼
        if not target_df.empty:
            st.markdown("#### ğŸ•’ æœ€è¿‘10æ¬¡å½•å…¥è®°å½•")
            
            recent_10_df = target_df.sort_values("date_dt", ascending=False).head(10)
            
            recent_display = recent_10_df[['date', 'price', 'quantity']].copy()
            
            recent_display.rename(columns={
                'date': 'å½•å…¥æ—¥æœŸ',
                'price': 'ä»·æ ¼ (Â¥)',
                'quantity': 'æ•°é‡ (å¼ )'
            }, inplace=True)
            
            st.dataframe(
                recent_display, 
                hide_index=True, 
                use_container_width=True,
                column_config={
                    "ä»·æ ¼ (Â¥)": st.column_config.NumberColumn(format="Â¥%d"),
                    "æ•°é‡ (å¼ )": st.column_config.NumberColumn(format="%d")
                }
            )
    
    # --- ğŸ“¥ æ•°æ®å¯¼å‡º (ç”¨äºå¤‡ä»½æˆ–è¿ç§») ---
    st.divider()
    st.markdown("### ğŸ“¥ æ•°æ®å¯¼å‡º (ç”¨äºå¤‡ä»½æˆ–è¿ç§»)")
    if not df.empty:
        csv_data = df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
        st.download_button(
            label="ä¸‹è½½å®Œæ•´çš„å¡ç‰Œæ•°æ® (CSV)",
            data=csv_data,
            file_name='card_data_full_export.csv',
            mime='text/csv',
            help='ç‚¹å‡»ä¸‹è½½ Supabase ä¸­çš„æ‰€æœ‰æ•°æ®ï¼Œç”¨äºå¤‡ä»½ã€‚'
        )
